{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 스페이스쉽 타이타닉 : 최적의 오토글루온 학습 경로\n",
                "\n",
                "AutoGluon을 활용하여 스페이스쉽 타이타닉 경진대회를 위한 머신러닝 파이프라인을 구현합니다. 탐색적 데이터 분석(EDA)을 통해 얻은 특성 엔지니어링을 적용하였으며, 성능 극대화를 위해 AutoGluon의 하이퍼파라미터를 최적화했습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Libraries loaded and paths set.\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from autogluon.tabular import TabularPredictor\n",
                "import os\n",
                "\n",
                "TRAIN_PATH = \"train.csv\"\n",
                "TEST_PATH = \"test.csv\"\n",
                "SUBMISSION_PATH = \"submission/submission_optimized.csv\"\n",
                "MODEL_PATH = \"AutogluonModels/ag-optimized-best-quality\"\n",
                "\n",
                "print(\"Libraries loaded and paths set.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 데이터 로드"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading data...\n",
                        "Combined shape: (12970, 14)\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading data...\")\n",
                "train_df = pd.read_csv(TRAIN_PATH)\n",
                "test_df = pd.read_csv(TEST_PATH)\n",
                "\n",
                "# Combine for consistent preprocessing\n",
                "train_len = len(train_df)\n",
                "all_data = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
                "\n",
                "print(f\"Combined shape: {all_data.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 특성 엔지니어링"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Spending features created.\n"
                    ]
                }
            ],
            "source": [
                "# Spending Columns\n",
                "spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
                "all_data[spending_cols] = all_data[spending_cols].fillna(0)\n",
                "all_data['TotalSpending'] = all_data[spending_cols].sum(axis=1)\n",
                "print(\"Spending features created.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 승객 정보 Features\n",
                "논리적인 규칙과 지출 습관을 바탕으로 냉동수면(CryoSleep), 나이(Age), VIP 여부, 그리고 목적지(Destination)의 결측치를 추론하여 채웁니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Personal status features engineered.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_37092\\3917088119.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
                        "  all_data['VIP'] = all_data['VIP'].fillna(False).astype(bool)\n"
                    ]
                }
            ],
            "source": [
                "# CryoSleep Imputation\n",
                "all_data.loc[(all_data['CryoSleep'].isna()) & (all_data['TotalSpending'] > 0), 'CryoSleep'] = False\n",
                "all_data.loc[(all_data['CryoSleep'].isna()) & (all_data['TotalSpending'] == 0), 'CryoSleep'] = True\n",
                "all_data['CryoSleep'] = all_data['CryoSleep'].astype(bool)\n",
                "\n",
                "# Age & AgeGroup\n",
                "all_data['Age'] = all_data['Age'].fillna(all_data['Age'].median())\n",
                "\n",
                "def update_age_group(age):\n",
                "    if age <= 4: return 'Baby'\n",
                "    elif age <= 12: return 'Child'\n",
                "    elif age <= 19: return 'Teenager'\n",
                "    elif age <= 40: return 'Adult'\n",
                "    elif age <= 60: return 'Middle Aged'\n",
                "    else: return 'Senior'\n",
                "\n",
                "all_data['AgeGroup'] = all_data['Age'].apply(update_age_group)\n",
                "\n",
                "# VIP Imputation\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['TotalSpending'] == 0), 'VIP'] = False\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['Age'] <= 19), 'VIP'] = False\n",
                "all_data['VIP'] = all_data['VIP'].fillna(False).astype(bool)\n",
                "\n",
                "# Destination Imputation\n",
                "dest_mode = all_data['Destination'].mode()[0]\n",
                "all_data['Destination'] = all_data['Destination'].fillna(dest_mode)\n",
                "\n",
                "print(\"Personal status features engineered.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Group and Family Features\n",
                "그룹 ID와 성씨(Surname)를 추출하여, 가족이나 그룹 내의 관계를 바탕으로 결측치를 정교하게 추론(Imputation)하는 데 활용합니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Group and family features engineered.\n"
                    ]
                }
            ],
            "source": [
                "# 1. Group & GroupSize\n",
                "all_data['Group'] = all_data['PassengerId'].str.split('_').str[0]\n",
                "group_sizes = all_data.groupby('Group').size()\n",
                "all_data['GroupSize'] = all_data['Group'].map(group_sizes)\n",
                "\n",
                "# 2. Surname & FamilySize\n",
                "all_data['Surname'] = all_data['Name'].str.split().str[-1]\n",
                "# Fill Surname within Group if possible\n",
                "all_data['Surname'] = all_data.groupby('Group')['Surname'].ffill()\n",
                "all_data['Surname'] = all_data.groupby('Group')['Surname'].bfill()\n",
                "\n",
                "# Map FamilySize\n",
                "family_counts = all_data['Surname'].value_counts()\n",
                "all_data['FamilySize'] = all_data['Surname'].map(family_counts)\n",
                "all_data.loc[all_data['Surname'].isna(), 'FamilySize'] = 1 # Default for unknown\n",
                "\n",
                "# 3. HomePlanet Imputation\n",
                "all_data['HomePlanet'] = all_data.groupby('Group')['HomePlanet'].ffill()\n",
                "all_data['HomePlanet'] = all_data.groupby('Group')['HomePlanet'].bfill()\n",
                "# Map based on Surname if still missing\n",
                "home_map = all_data.dropna(subset=['HomePlanet']).groupby('Surname')['HomePlanet'].agg(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
                "all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['Surname'].map(home_map))\n",
                "all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['HomePlanet'].mode()[0])\n",
                "\n",
                "print(\"Group and family features engineered.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 객식(Cabin) Features\n",
                "객실 정보 세분화 및 복원: Cabin 데이터를 Deck(데크), Num(번호), Side(좌우)로 분리하고, 그룹 내 다른 구성원의 정보를 활용하여 누락된 객실 값을 정교하게 채웁니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cabin features engineered.\n"
                    ]
                }
            ],
            "source": [
                "# Split Cabin\n",
                "all_data[['Deck', 'Num', 'Side']] = all_data['Cabin'].str.split('/', expand=True)\n",
                "\n",
                "# Fill within Group\n",
                "for col in ['Deck', 'Num', 'Side']:\n",
                "    all_data[col] = all_data.groupby('Group')[col].ffill()\n",
                "    all_data[col] = all_data.groupby('Group')[col].bfill()\n",
                "\n",
                "# Process Num (convert to numeric)\n",
                "if all_data['Num'].isna().sum() > 0:\n",
                "    all_data['Num'] = pd.to_numeric(all_data['Num'], errors='coerce')\n",
                "    all_data['Num'] = all_data['Num'].fillna(all_data['Num'].median())\n",
                "\n",
                "print(\"Cabin features engineered.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 데이터 전처리\n",
                "모델링을 위한 데이터 준비: 과적합(Overfitting)을 유발할 수 있는 고유 식별값 및 중복 열(PassengerId, Name, Cabin, Surname, Group)을 제거하고, 데이터를 다시 학습용(Train)과 테스트용(Test)으로 분리합니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Final Train Shape: (8693, 18)\n",
                        "Final Test Shape: (4277, 17)\n",
                        "Features: ['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Transported', 'TotalSpending', 'AgeGroup', 'GroupSize', 'FamilySize', 'Deck', 'Num', 'Side']\n"
                    ]
                }
            ],
            "source": [
                "cols_to_drop = ['PassengerId', 'Name', 'Cabin', 'Surname', 'Group']\n",
                "\n",
                "train_final = all_data.iloc[:train_len].copy().drop(columns=cols_to_drop)\n",
                "test_final = all_data.iloc[train_len:].copy().drop(columns=cols_to_drop)\n",
                "\n",
                "# Ensure target is dropped from test if present\n",
                "if 'Transported' in test_final.columns:\n",
                "    test_final = test_final.drop(columns=['Transported'])\n",
                "\n",
                "# Train target formatting\n",
                "label = 'Transported'\n",
                "train_final[label] = train_final[label].astype(bool)\n",
                "\n",
                "print(f\"Final Train Shape: {train_final.shape}\")\n",
                "print(f\"Final Test Shape: {test_final.shape}\")\n",
                "print(f\"Features: {list(train_final.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. AutoGluon 모델 학습\n",
                "모델 최적화 및 학습: 최상의 앙상블 성능을 위해 best_quality 프리셋을 사용하며, 1시간의 제한 시간, 8겹의 배깅(Bagging), 그리고 2단계 스태킹(Stacking)을 적용합니다. 또한, 과적합을 방지하기 위해 CatBoost 모델의 깊이를 6으로 제한합니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "CatBoost를 단일 알고리즘으로 사용하되, 8-폴드 배깅(Bagging)과 2단계 스태킹(Stacking) 기술을 적용한 CatBoost 전용 앙상블 모델입니다.<br>best_quality로 1시간 학습 : WeightedEnsemble_L2가 최고 모델로 선정되었으며, 0.8227점이 나왔습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ag-optimized-best-quality\"\n",
                        "Verbosity: 2 (Standard Logging)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting AutoGluon Training...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "=================== System Info ===================\n",
                        "AutoGluon Version:  1.5.0\n",
                        "Python Version:     3.11.14\n",
                        "Operating System:   Windows\n",
                        "Platform Machine:   AMD64\n",
                        "Platform Version:   10.0.22631\n",
                        "CPU Count:          16\n",
                        "Pytorch Version:    2.9.1+cpu\n",
                        "CUDA Version:       CUDA is not available\n",
                        "Memory Avail:       13.60 GB / 31.72 GB (42.9%)\n",
                        "Disk Space Avail:   251.52 GB / 476.83 GB (52.7%)\n",
                        "===================================================\n",
                        "Presets specified: ['best_quality']\n",
                        "Using hyperparameters preset: hyperparameters='zeroshot'\n",
                        "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
                        "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=8, num_bag_sets=1\n",
                        "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
                        "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
                        "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
                        "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
                        "2026-02-12 11:57:12,432\tINFO worker.py:2014 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
                        "c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\ray\\_private\\worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
                        "  warnings.warn(\n",
                        "\t\tContext path: \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\AutogluonModels\\ag-optimized-best-quality\\ds_sub_fit\\sub_fit_ho\"\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Running DyStack sub-fit ...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Beginning AutoGluon training ... Time limit = 890s\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m AutoGluon will save models to \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\AutogluonModels\\ag-optimized-best-quality\\ds_sub_fit\\sub_fit_ho\"\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Train Data Rows:    7727\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Train Data Columns: 17\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Label Column:       Transported\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Problem Type:       binary\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Preprocessing data ...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Using Feature Generators to preprocess the data ...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tAvailable Memory:                    12715.31 MB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tTrain Data (Original)  Memory Usage: 2.88 MB (0.0% of available memory)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tStage 1 Generators:\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tStage 2 Generators:\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tStage 3 Generators:\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tStage 4 Generators:\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tStage 5 Generators:\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t('bool', [])   : 2 | ['CryoSleep', 'VIP']\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t('float', [])  : 9 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t('int', [])    : 1 | ['GroupSize']\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t('object', []) : 5 | ['HomePlanet', 'Destination', 'AgeGroup', 'Deck', 'Side']\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t('category', [])  : 5 | ['HomePlanet', 'Destination', 'AgeGroup', 'Deck', 'Side']\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t('float', [])     : 9 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t('int', [])       : 1 | ['GroupSize']\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t\t('int', ['bool']) : 2 | ['CryoSleep', 'VIP']\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.1s = Fit runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t17 features in original data used to generate 17 features in processed data.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.64 MB (0.0% of available memory)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Data preprocessing and feature engineering runtime = 0.14s ...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m User-specified model hyperparameters to be fit:\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m {\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m }\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 395.40s of the 889.85s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.18%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8237\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t3.17s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.19s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 378.65s of the 873.10s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.20%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8166\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t2.33s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.1s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 371.47s of the 865.92s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/11.2 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8012\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t1.73s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.84s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 368.70s of the 863.15s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/12.2 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8008\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t3.18s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.77s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 363.04s of the 857.50s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.23%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8204\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t130.15s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.07s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 228.66s of the 723.12s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/11.9 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8024\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t1.47s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.46s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 226.55s of the 721.00s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/12.1 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.7988\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t1.17s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.6s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 224.55s of the 719.01s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.06%)\n",
                        "\u001b[36m(_ray_fit pid=23380)\u001b[0m No improvement since epoch 9: early stopping\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8184\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t30.21s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.31s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 189.41s of the 683.87s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.19%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8138\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t3.56s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.17s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 180.35s of the 674.80s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
                        "\u001b[36m(_ray_fit pid=11468)\u001b[0m c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
                        "\u001b[36m(_ray_fit pid=11468)\u001b[0m   warnings.warn(\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8034\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t127.66s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.31s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 46.86s of the 541.32s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.63%)\n",
                        "\u001b[36m(_ray_fit pid=21312)\u001b[0m c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
                        "\u001b[36m(_ray_fit pid=21312)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8117\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t6.26s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.24s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 35.42s of the 529.87s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.34%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t9.91s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.07s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 20.14s of the 514.59s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
                        "\u001b[36m(_ray_fit pid=6924)\u001b[0m c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
                        "\u001b[36m(_ray_fit pid=6924)\u001b[0m   warnings.warn(\n",
                        "\u001b[36m(_ray_fit pid=24532)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 4)\n",
                        "\u001b[36m(_ray_fit pid=33920)\u001b[0m c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
                        "\u001b[36m(_ray_fit pid=33920)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.7612\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t19.72s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.34s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 488.69s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/9.7 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tEnsemble Weights: {'CatBoost_r177_BAG_L1': 1.0}\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.52s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.0s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 325.34s of the 488.00s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.26%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8289\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t6.02s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.21s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 312.13s of the 474.80s of remaining time.\n",
                        "\u001b[36m(_ray_fit pid=39288)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 4)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.22%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.831\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t5.79s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.15s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 298.70s of the 461.36s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/11.8 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8281\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t2.76s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.5s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 295.32s of the 457.98s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/12.4 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.825\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t2.71s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.5s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 292.01s of the 454.67s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.29%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m E0212 12:05:38.807000000 19724 external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_windows.cc:360] on_accept error: The I/O operation has been aborted because of either a thread exit or an application request.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8315\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t120.12s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.09s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 163.78s of the 326.44s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/12.2 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8224\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t1.45s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.36s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 161.84s of the 324.51s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/12.3 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8237\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t1.22s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.43s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 160.07s of the 322.73s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.10%)\n",
                        "\u001b[36m(_ray_fit pid=36924)\u001b[0m No improvement since epoch 1: early stopping\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.825\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t29.14s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.28s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 126.07s of the 288.73s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.27%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8301\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t4.14s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.14s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 117.02s of the 279.68s of remaining time.\n",
                        "\u001b[36m(_ray_fit pid=25680)\u001b[0m No improvement since epoch 6: early stopping\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.08%)\n",
                        "\u001b[36m(_ray_fit pid=22616)\u001b[0m c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
                        "\u001b[36m(_ray_fit pid=22616)\u001b[0m   warnings.warn(\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8239\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t87.89s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.27s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 23.58s of the 186.24s of remaining time.\n",
                        "\u001b[36m(_ray_fit pid=33000)\u001b[0m c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
                        "\u001b[36m(_ray_fit pid=33000)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.73%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8292\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t11.83s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.18s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 6.79s of the 169.46s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.32%)\n",
                        "\u001b[36m(_ray_fit pid=35616)\u001b[0m \tRan out of time, early stopping on iteration 155.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8307\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t5.61s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.1s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 157.33s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/11.0 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L2': 1.0}\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8315\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.39s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.0s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 156.91s of the 156.82s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.21%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8314\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t3.7s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.08s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: LightGBM_BAG_L3 ... Training model for up to 146.37s of the 146.28s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.24%)\n",
                        "\u001b[36m(_ray_fit pid=25756)\u001b[0m \tRan out of time, early stopping on iteration 163.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8355\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t5.96s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.14s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 132.44s of the 132.35s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/11.9 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8279\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t2.6s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.45s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 129.24s of the 129.15s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/12.4 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8287\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t2.73s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.46s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: CatBoost_BAG_L3 ... Training model for up to 125.94s of the 125.85s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.28%)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8341\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t81.37s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.09s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 37.05s of the 36.96s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/12.4 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8275\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t1.28s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.37s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 35.31s of the 35.22s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/12.5 GB\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8227\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.82s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.29s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 34.10s of the 34.01s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.09%)\n",
                        "\u001b[36m(_ray_fit pid=32180)\u001b[0m No improvement since epoch 0: early stopping\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8314\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t33.27s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.39s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the -4.41s of remaining time.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/9.3 GB\n",
                        "\u001b[36m(_ray_fit pid=40796)\u001b[0m No improvement since epoch 6: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L3': 1.0}\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.8355\t = Validation score   (accuracy)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.43s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t0.0s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m AutoGluon training complete, total runtime = 894.86s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 245.9 rows/s (966 batch size)\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (7727 rows).\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m \t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\AutogluonModels\\ag-optimized-best-quality\\ds_sub_fit\\sub_fit_ho\")\n",
                        "\u001b[36m(_dystack pid=32400)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
                        "Leaderboard on holdout data (DyStack):\n",
                        "                        model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
                        "0             LightGBM_BAG_L3       0.821946   0.835512    accuracy       12.335907       7.824871  625.135494                 0.282516                0.142203           5.963985            3       True         29\n",
                        "1         WeightedEnsemble_L4       0.821946   0.835512    accuracy       12.357610       7.826430  625.569832                 0.021703                0.001559           0.434337            4       True         36\n",
                        "2      NeuralNetFastAI_BAG_L2       0.820911   0.825029    accuracy        8.682977       4.751889  369.658370                 0.776509                0.275171          29.139006            2       True         22\n",
                        "3     RandomForestGini_BAG_L3       0.816770   0.827876    accuracy       12.251011       8.135440  621.773853                 0.197620                0.452772           2.602344            3       True         30\n",
                        "4           LightGBMXT_BAG_L2       0.815735   0.828912    accuracy        8.217861       4.687594  346.539764                 0.311392                0.210876           6.020400            2       True         15\n",
                        "5     RandomForestEntr_BAG_L3       0.815735   0.828653    accuracy       12.305820       8.146063  621.901845                 0.252429                0.463395           2.730336            3       True         31\n",
                        "6       ExtraTreesGini_BAG_L2       0.813665   0.822441    accuracy        8.153497       4.836803  341.965508                 0.247029                0.360085           1.446144            2       True         20\n",
                        "7      NeuralNetFastAI_BAG_L3       0.813665   0.831371    accuracy       12.811973       8.074772  652.441401                 0.758583                0.392104          33.269892            3       True         35\n",
                        "8       ExtraTreesEntr_BAG_L2       0.812629   0.823735    accuracy        8.138418       4.910302  341.739606                 0.231949                0.433584           1.220242            2       True         21\n",
                        "9             CatBoost_BAG_L3       0.812629   0.834088    accuracy       12.319378       7.770396  700.546222                 0.265988                0.087728          81.374713            3       True         32\n",
                        "10    RandomForestGini_BAG_L2       0.811594   0.828135    accuracy        8.114244       4.972716  343.276727                 0.207775                0.495998           2.757363            2       True         17\n",
                        "11            LightGBM_BAG_L2       0.811594   0.830982    accuracy        8.161110       4.628957  346.305120                 0.254641                0.152239           5.785755            2       True         16\n",
                        "12      NeuralNetTorch_BAG_L2       0.811594   0.823864    accuracy        8.382721       4.746321  428.404651                 0.476253                0.269603          87.885287            2       True         24\n",
                        "13             XGBoost_BAG_L2       0.811594   0.830076    accuracy        8.438931       4.617664  344.655883                 0.532462                0.140946           4.136519            2       True         23\n",
                        "14          LightGBMXT_BAG_L3       0.811594   0.831371    accuracy       12.348972       7.766636  622.871051                 0.295581                0.083968           3.699542            3       True         28\n",
                        "15       CatBoost_r177_BAG_L1       0.810559   0.823864    accuracy        0.273769       0.072698    9.907165                 0.273769                0.072698           9.907165            1       True         12\n",
                        "16        WeightedEnsemble_L2       0.810559   0.823864    accuracy        0.297538       0.076082   10.426103                 0.023768                0.003383           0.518938            2       True         14\n",
                        "17            CatBoost_BAG_L2       0.810559   0.831500    accuracy        8.206992       4.568647  460.637168                 0.300524                0.091929         120.117804            2       True         19\n",
                        "18        WeightedEnsemble_L3       0.810559   0.831500    accuracy        8.235917       4.571312  461.031152                 0.028924                0.002664           0.393984            3       True         27\n",
                        "19       CatBoost_r177_BAG_L2       0.809524   0.830723    accuracy        8.181234       4.572972  346.127984                 0.274765                0.096254           5.608620            2       True         26\n",
                        "20       LightGBMLarge_BAG_L1       0.808489   0.811699    accuracy        0.377779       0.236083    6.257737                 0.377779                0.236083           6.257737            1       True         11\n",
                        "21    RandomForestEntr_BAG_L2       0.808489   0.825029    accuracy        8.096108       4.973175  343.224757                 0.189639                0.496457           2.705393            2       True         18\n",
                        "22       LightGBMLarge_BAG_L2       0.808489   0.829170    accuracy        8.250453       4.659525  352.348976                 0.343984                0.182807          11.829612            2       True         25\n",
                        "23      ExtraTreesEntr_BAG_L3       0.808489   0.822700    accuracy       12.292938       7.975579  619.989077                 0.239547                0.292911           0.817567            3       True         34\n",
                        "24            LightGBM_BAG_L1       0.807453   0.816617    accuracy        0.276804       0.101590    2.327854                 0.276804                0.101590           2.327854            1       True          2\n",
                        "25      ExtraTreesGini_BAG_L3       0.807453   0.827488    accuracy       12.303586       8.049338  620.455166                 0.250195                0.366670           1.283657            3       True         33\n",
                        "26    RandomForestEntr_BAG_L1       0.806418   0.800828    accuracy        0.264333       0.765434    3.176345                 0.264333                0.765434           3.176345            1       True          4\n",
                        "27             XGBoost_BAG_L1       0.806418   0.813770    accuracy        0.571972       0.172175    3.564601                 0.571972                0.172175           3.564601            1       True          9\n",
                        "28            CatBoost_BAG_L1       0.806418   0.820370    accuracy        1.026496       0.072767  130.150894                 1.026496                0.072767         130.150894            1       True          5\n",
                        "29      ExtraTreesEntr_BAG_L1       0.805383   0.798758    accuracy        0.332915       0.598044    1.169259                 0.332915                0.598044           1.169259            1       True          7\n",
                        "30    RandomForestGini_BAG_L1       0.804348   0.801217    accuracy        0.240419       0.844827    1.729494                 0.240419                0.844827           1.729494            1       True          3\n",
                        "31          LightGBMXT_BAG_L1       0.804348   0.823735    accuracy        0.846037       0.191454    3.170634                 0.846037                0.191454           3.170634            1       True          1\n",
                        "32      ExtraTreesGini_BAG_L1       0.800207   0.802381    accuracy        0.295329       0.459800    1.473796                 0.295329                0.459800           1.473796            1       True          6\n",
                        "33     NeuralNetFastAI_BAG_L1       0.796066   0.818429    accuracy        2.260866       0.309192   30.214497                 2.260866                0.309192          30.214497            1       True          8\n",
                        "34      NeuralNetTorch_BAG_L1       0.790890   0.803417    accuracy        0.519351       0.312052  127.661952                 0.519351                0.312052         127.661952            1       True         10\n",
                        "35  NeuralNetTorch_r79_BAG_L1       0.765010   0.761227    accuracy        0.620398       0.340602   19.715136                 0.620398                0.340602          19.715136            1       True         13\n",
                        "\t2\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
                        "\t925s\t = DyStack   runtime |\t2675s\t = Remaining runtime\n",
                        "Starting main fit with num_stack_levels=2.\n",
                        "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=2)`\n",
                        "Beginning AutoGluon training ... Time limit = 2675s\n",
                        "AutoGluon will save models to \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\AutogluonModels\\ag-optimized-best-quality\"\n",
                        "Train Data Rows:    8693\n",
                        "Train Data Columns: 17\n",
                        "Label Column:       Transported\n",
                        "Problem Type:       binary\n",
                        "Preprocessing data ...\n",
                        "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
                        "Using Feature Generators to preprocess the data ...\n",
                        "Fitting AutoMLPipelineFeatureGenerator...\n",
                        "\tAvailable Memory:                    9831.08 MB\n",
                        "\tTrain Data (Original)  Memory Usage: 3.24 MB (0.0% of available memory)\n",
                        "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
                        "\tStage 1 Generators:\n",
                        "\t\tFitting AsTypeFeatureGenerator...\n",
                        "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
                        "\tStage 2 Generators:\n",
                        "\t\tFitting FillNaFeatureGenerator...\n",
                        "\tStage 3 Generators:\n",
                        "\t\tFitting IdentityFeatureGenerator...\n",
                        "\t\tFitting CategoryFeatureGenerator...\n",
                        "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
                        "\tStage 4 Generators:\n",
                        "\t\tFitting DropUniqueFeatureGenerator...\n",
                        "\tStage 5 Generators:\n",
                        "\t\tFitting DropDuplicatesFeatureGenerator...\n",
                        "\tTypes of features in original data (raw dtype, special dtypes):\n",
                        "\t\t('bool', [])   : 2 | ['CryoSleep', 'VIP']\n",
                        "\t\t('float', [])  : 9 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\t\t('int', [])    : 1 | ['GroupSize']\n",
                        "\t\t('object', []) : 5 | ['HomePlanet', 'Destination', 'AgeGroup', 'Deck', 'Side']\n",
                        "\tTypes of features in processed data (raw dtype, special dtypes):\n",
                        "\t\t('category', [])  : 5 | ['HomePlanet', 'Destination', 'AgeGroup', 'Deck', 'Side']\n",
                        "\t\t('float', [])     : 9 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\t\t('int', [])       : 1 | ['GroupSize']\n",
                        "\t\t('int', ['bool']) : 2 | ['CryoSleep', 'VIP']\n",
                        "\t0.1s = Fit runtime\n",
                        "\t17 features in original data used to generate 17 features in processed data.\n",
                        "\tTrain Data (Processed) Memory Usage: 0.72 MB (0.0% of available memory)\n",
                        "Data preprocessing and feature engineering runtime = 0.15s ...\n",
                        "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
                        "\tTo change this, specify the eval_metric parameter of Predictor()\n",
                        "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
                        "User-specified model hyperparameters to be fit:\n",
                        "{\n",
                        "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
                        "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
                        "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
                        "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
                        "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
                        "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
                        "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
                        "}\n",
                        "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
                        "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1188.39s of the 2674.54s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
                        "\t0.8201\t = Validation score   (accuracy)\n",
                        "\t4.54s\t = Training   runtime\n",
                        "\t0.28s\t = Validation runtime\n",
                        "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1174.40s of the 2660.55s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
                        "\t0.8171\t = Validation score   (accuracy)\n",
                        "\t4.6s\t = Training   runtime\n",
                        "\t0.19s\t = Validation runtime\n",
                        "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1162.58s of the 2648.73s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.0 GB\n",
                        "\t0.8039\t = Validation score   (accuracy)\n",
                        "\t1.9s\t = Training   runtime\n",
                        "\t0.54s\t = Validation runtime\n",
                        "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1159.99s of the 2646.14s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.9 GB\n",
                        "\t0.801\t = Validation score   (accuracy)\n",
                        "\t1.6s\t = Training   runtime\n",
                        "\t0.57s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1157.67s of the 2643.82s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.99%)\n",
                        "\t0.8227\t = Validation score   (accuracy)\n",
                        "\t91.78s\t = Training   runtime\n",
                        "\t0.08s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1058.20s of the 2544.35s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.7 GB\n",
                        "\t0.8018\t = Validation score   (accuracy)\n",
                        "\t1.38s\t = Training   runtime\n",
                        "\t0.57s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1055.97s of the 2542.11s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.8 GB\n",
                        "\t0.804\t = Validation score   (accuracy)\n",
                        "\t1.29s\t = Training   runtime\n",
                        "\t0.5s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1053.97s of the 2540.11s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.08%)\n",
                        "\t0.8202\t = Validation score   (accuracy)\n",
                        "\t34.65s\t = Training   runtime\n",
                        "\t0.33s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1013.99s of the 2500.14s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.25%)\n",
                        "\t0.8186\t = Validation score   (accuracy)\n",
                        "\t4.41s\t = Training   runtime\n",
                        "\t1.02s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1004.16s of the 2490.30s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.06%)\n",
                        "\t0.8028\t = Validation score   (accuracy)\n",
                        "\t102.53s\t = Training   runtime\n",
                        "\t0.35s\t = Validation runtime\n",
                        "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 895.20s of the 2381.34s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.86%)\n",
                        "\t0.813\t = Validation score   (accuracy)\n",
                        "\t6.9s\t = Training   runtime\n",
                        "\t0.15s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 882.54s of the 2368.68s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.41%)\n",
                        "\t0.8242\t = Validation score   (accuracy)\n",
                        "\t14.17s\t = Training   runtime\n",
                        "\t0.07s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 862.72s of the 2348.86s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.8018\t = Validation score   (accuracy)\n",
                        "\t143.0s\t = Training   runtime\n",
                        "\t0.3s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 713.70s of the 2199.85s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.38%)\n",
                        "\t0.8181\t = Validation score   (accuracy)\n",
                        "\t10.07s\t = Training   runtime\n",
                        "\t0.6s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 695.47s of the 2181.61s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.09%)\n",
                        "\t0.8173\t = Validation score   (accuracy)\n",
                        "\t105.61s\t = Training   runtime\n",
                        "\t0.74s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 581.65s of the 2067.79s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.97%)\n",
                        "\t0.822\t = Validation score   (accuracy)\n",
                        "\t104.46s\t = Training   runtime\n",
                        "\t0.14s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 468.48s of the 1954.63s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.15%)\n",
                        "\t0.8143\t = Validation score   (accuracy)\n",
                        "\t4.93s\t = Training   runtime\n",
                        "\t0.45s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 458.04s of the 1944.18s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.8055\t = Validation score   (accuracy)\n",
                        "\t168.72s\t = Training   runtime\n",
                        "\t0.39s\t = Validation runtime\n",
                        "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 283.13s of the 1769.27s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.77%)\n",
                        "\t0.8131\t = Validation score   (accuracy)\n",
                        "\t9.29s\t = Training   runtime\n",
                        "\t0.97s\t = Validation runtime\n",
                        "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 267.69s of the 1753.84s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.2 GB\n",
                        "\t0.8047\t = Validation score   (accuracy)\n",
                        "\t1.37s\t = Training   runtime\n",
                        "\t0.52s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 265.64s of the 1751.79s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.90%)\n",
                        "\t0.8187\t = Validation score   (accuracy)\n",
                        "\t71.81s\t = Training   runtime\n",
                        "\t0.07s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 187.93s of the 1674.08s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.08%)\n",
                        "\t0.817\t = Validation score   (accuracy)\n",
                        "\t21.94s\t = Training   runtime\n",
                        "\t0.19s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 161.20s of the 1647.35s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=5.79%)\n",
                        "\t0.8214\t = Validation score   (accuracy)\n",
                        "\t37.4s\t = Training   runtime\n",
                        "\t0.08s\t = Validation runtime\n",
                        "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 117.02s of the 1603.16s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.6 GB\n",
                        "\t0.8024\t = Validation score   (accuracy)\n",
                        "\t2.81s\t = Training   runtime\n",
                        "\t0.53s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 113.52s of the 1599.67s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.78%)\n",
                        "\t0.817\t = Validation score   (accuracy)\n",
                        "\t11.84s\t = Training   runtime\n",
                        "\t0.51s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 93.32s of the 1579.46s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.08%)\n",
                        "\t0.8148\t = Validation score   (accuracy)\n",
                        "\t71.6s\t = Training   runtime\n",
                        "\t0.91s\t = Validation runtime\n",
                        "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 13.42s of the 1499.56s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
                        "\t0.8185\t = Validation score   (accuracy)\n",
                        "\t5.39s\t = Training   runtime\n",
                        "\t1.19s\t = Validation runtime\n",
                        "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1484.51s of remaining time.\n",
                        "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/10.2 GB\n",
                        "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 1.0}\n",
                        "\t0.8242\t = Validation score   (accuracy)\n",
                        "\t0.44s\t = Training   runtime\n",
                        "\t0.0s\t = Validation runtime\n",
                        "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 989.10s of the 1483.91s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.32%)\n",
                        "\t0.8268\t = Validation score   (accuracy)\n",
                        "\t7.14s\t = Training   runtime\n",
                        "\t0.2s\t = Validation runtime\n",
                        "Fitting model: LightGBM_BAG_L2 ... Training model for up to 974.32s of the 1469.13s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.32%)\n",
                        "\t0.8316\t = Validation score   (accuracy)\n",
                        "\t5.28s\t = Training   runtime\n",
                        "\t0.12s\t = Validation runtime\n",
                        "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 961.12s of the 1455.93s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/8.9 GB\n",
                        "\t0.8224\t = Validation score   (accuracy)\n",
                        "\t4.1s\t = Training   runtime\n",
                        "\t0.75s\t = Validation runtime\n",
                        "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 956.09s of the 1450.89s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/10.1 GB\n",
                        "\t0.827\t = Validation score   (accuracy)\n",
                        "\t4.18s\t = Training   runtime\n",
                        "\t0.51s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L2 ... Training model for up to 951.30s of the 1446.10s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.18%)\n",
                        "\t0.8295\t = Validation score   (accuracy)\n",
                        "\t68.38s\t = Training   runtime\n",
                        "\t0.1s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 876.12s of the 1370.93s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/10.0 GB\n",
                        "\t0.8219\t = Validation score   (accuracy)\n",
                        "\t1.28s\t = Training   runtime\n",
                        "\t0.53s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 874.15s of the 1368.96s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/10.1 GB\n",
                        "\t0.8238\t = Validation score   (accuracy)\n",
                        "\t1.18s\t = Training   runtime\n",
                        "\t0.59s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 872.26s of the 1367.06s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.17%)\n",
                        "\t0.8247\t = Validation score   (accuracy)\n",
                        "\t38.57s\t = Training   runtime\n",
                        "\t0.35s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L2 ... Training model for up to 826.21s of the 1321.01s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.44%)\n",
                        "\t0.8325\t = Validation score   (accuracy)\n",
                        "\t6.03s\t = Training   runtime\n",
                        "\t0.16s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 814.07s of the 1308.87s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.10%)\n",
                        "\t0.8205\t = Validation score   (accuracy)\n",
                        "\t46.9s\t = Training   runtime\n",
                        "\t0.32s\t = Validation runtime\n",
                        "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 761.55s of the 1256.36s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.37%)\n",
                        "\t0.83\t = Validation score   (accuracy)\n",
                        "\t21.7s\t = Training   runtime\n",
                        "\t0.23s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 732.04s of the 1226.84s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.22%)\n",
                        "\t0.8292\t = Validation score   (accuracy)\n",
                        "\t27.1s\t = Training   runtime\n",
                        "\t0.1s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 696.68s of the 1191.48s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.10%)\n",
                        "\t0.8281\t = Validation score   (accuracy)\n",
                        "\t118.62s\t = Training   runtime\n",
                        "\t0.33s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 572.23s of the 1067.03s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.50%)\n",
                        "\t0.8317\t = Validation score   (accuracy)\n",
                        "\t8.56s\t = Training   runtime\n",
                        "\t0.2s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 557.57s of the 1052.38s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.18%)\n",
                        "\t0.8255\t = Validation score   (accuracy)\n",
                        "\t107.01s\t = Training   runtime\n",
                        "\t0.64s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 443.57s of the 938.37s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.22%)\n",
                        "\t0.8322\t = Validation score   (accuracy)\n",
                        "\t187.27s\t = Training   runtime\n",
                        "\t0.12s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 248.18s of the 742.98s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
                        "\t0.825\t = Validation score   (accuracy)\n",
                        "\t3.54s\t = Training   runtime\n",
                        "\t0.13s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 239.68s of the 734.49s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.10%)\n",
                        "\t0.8224\t = Validation score   (accuracy)\n",
                        "\t63.59s\t = Training   runtime\n",
                        "\t0.3s\t = Validation runtime\n",
                        "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 171.50s of the 666.30s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.62%)\n",
                        "\t0.8317\t = Validation score   (accuracy)\n",
                        "\t15.64s\t = Training   runtime\n",
                        "\t0.19s\t = Validation runtime\n",
                        "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 151.52s of the 646.32s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.5 GB\n",
                        "\t0.8226\t = Validation score   (accuracy)\n",
                        "\t1.44s\t = Training   runtime\n",
                        "\t0.52s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 149.40s of the 644.21s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.07%)\n",
                        "\t0.8309\t = Validation score   (accuracy)\n",
                        "\t49.35s\t = Training   runtime\n",
                        "\t0.08s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 94.44s of the 589.25s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.18%)\n",
                        "\t0.8254\t = Validation score   (accuracy)\n",
                        "\t29.28s\t = Training   runtime\n",
                        "\t0.42s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 58.16s of the 552.96s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.29%)\n",
                        "\t0.8286\t = Validation score   (accuracy)\n",
                        "\t46.53s\t = Training   runtime\n",
                        "\t0.11s\t = Validation runtime\n",
                        "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 2.65s of the 497.45s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/8.9 GB\n",
                        "\t0.8257\t = Validation score   (accuracy)\n",
                        "\t13.84s\t = Training   runtime\n",
                        "\t0.56s\t = Validation runtime\n",
                        "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 482.25s of remaining time.\n",
                        "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/9.6 GB\n",
                        "\tEnsemble Weights: {'XGBoost_BAG_L2': 0.958, 'NeuralNetTorch_r79_BAG_L2': 0.042}\n",
                        "\t0.8326\t = Validation score   (accuracy)\n",
                        "\t0.38s\t = Training   runtime\n",
                        "\t0.0s\t = Validation runtime\n",
                        "Fitting 108 L3 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 481.85s of the 481.75s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.33%)\n",
                        "\t0.8353\t = Validation score   (accuracy)\n",
                        "\t4.21s\t = Training   runtime\n",
                        "\t0.12s\t = Validation runtime\n",
                        "Fitting model: LightGBM_BAG_L3 ... Training model for up to 471.50s of the 471.41s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.34%)\n",
                        "\t0.8404\t = Validation score   (accuracy)\n",
                        "\t4.05s\t = Training   runtime\n",
                        "\t0.12s\t = Validation runtime\n",
                        "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 461.59s of the 461.49s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/8.8 GB\n",
                        "\t0.8333\t = Validation score   (accuracy)\n",
                        "\t2.35s\t = Training   runtime\n",
                        "\t0.61s\t = Validation runtime\n",
                        "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 458.51s of the 458.41s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.6 GB\n",
                        "\t0.8323\t = Validation score   (accuracy)\n",
                        "\t2.37s\t = Training   runtime\n",
                        "\t0.53s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L3 ... Training model for up to 455.47s of the 455.37s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.37%)\n",
                        "\t0.8391\t = Validation score   (accuracy)\n",
                        "\t73.32s\t = Training   runtime\n",
                        "\t0.1s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 376.65s of the 376.56s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.4 GB\n",
                        "\t0.8276\t = Validation score   (accuracy)\n",
                        "\t0.96s\t = Training   runtime\n",
                        "\t0.4s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 375.17s of the 375.08s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.5 GB\n",
                        "\t0.8293\t = Validation score   (accuracy)\n",
                        "\t1.28s\t = Training   runtime\n",
                        "\t0.65s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 373.10s of the 373.01s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.17%)\n",
                        "\t0.8333\t = Validation score   (accuracy)\n",
                        "\t39.18s\t = Training   runtime\n",
                        "\t0.33s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L3 ... Training model for up to 326.21s of the 326.11s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.49%)\n",
                        "\t0.8381\t = Validation score   (accuracy)\n",
                        "\t6.65s\t = Training   runtime\n",
                        "\t0.18s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 314.18s of the 314.08s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.11%)\n",
                        "\t0.8307\t = Validation score   (accuracy)\n",
                        "\t48.69s\t = Training   runtime\n",
                        "\t0.38s\t = Validation runtime\n",
                        "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 259.76s of the 259.66s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.09%)\n",
                        "\t0.8371\t = Validation score   (accuracy)\n",
                        "\t16.96s\t = Training   runtime\n",
                        "\t0.17s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r177_BAG_L3 ... Training model for up to 234.62s of the 234.52s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.51%)\n",
                        "\t0.8398\t = Validation score   (accuracy)\n",
                        "\t24.32s\t = Training   runtime\n",
                        "\t0.11s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r79_BAG_L3 ... Training model for up to 202.27s of the 202.18s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.09%)\n",
                        "\t0.8337\t = Validation score   (accuracy)\n",
                        "\t74.28s\t = Training   runtime\n",
                        "\t0.32s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r131_BAG_L3 ... Training model for up to 120.37s of the 120.28s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.50%)\n",
                        "\t0.839\t = Validation score   (accuracy)\n",
                        "\t8.83s\t = Training   runtime\n",
                        "\t0.16s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r191_BAG_L3 ... Training model for up to 105.77s of the 105.67s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.17%)\n",
                        "\t0.833\t = Validation score   (accuracy)\n",
                        "\t93.7s\t = Training   runtime\n",
                        "\t0.55s\t = Validation runtime\n",
                        "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 3.51s of remaining time.\n",
                        "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/6.8 GB\n",
                        "\tEnsemble Weights: {'LightGBM_BAG_L3': 1.0}\n",
                        "\t0.8404\t = Validation score   (accuracy)\n",
                        "\t0.64s\t = Training   runtime\n",
                        "\t0.0s\t = Validation runtime\n",
                        "AutoGluon training complete, total runtime = 2671.87s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 95.7 rows/s (1087 batch size)\n",
                        "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (8693 rows).\n",
                        "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
                        "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\AutogluonModels\\ag-optimized-best-quality\")\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== [결과 리더보드] ===\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>model</th>\n",
                            "      <th>score_val</th>\n",
                            "      <th>pred_time_val</th>\n",
                            "      <th>fit_time</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>LightGBM_BAG_L3</td>\n",
                            "      <td>0.840446</td>\n",
                            "      <td>17.194179</td>\n",
                            "      <td>1631.768937</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>WeightedEnsemble_L4</td>\n",
                            "      <td>0.840446</td>\n",
                            "      <td>17.197174</td>\n",
                            "      <td>1632.407176</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>CatBoost_r177_BAG_L3</td>\n",
                            "      <td>0.839756</td>\n",
                            "      <td>17.186764</td>\n",
                            "      <td>1652.045540</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>CatBoost_BAG_L3</td>\n",
                            "      <td>0.839066</td>\n",
                            "      <td>17.174221</td>\n",
                            "      <td>1701.040648</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>LightGBM_r131_BAG_L3</td>\n",
                            "      <td>0.838951</td>\n",
                            "      <td>17.237628</td>\n",
                            "      <td>1636.552284</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>64</th>\n",
                            "      <td>NeuralNetTorch_BAG_L1</td>\n",
                            "      <td>0.802830</td>\n",
                            "      <td>0.353503</td>\n",
                            "      <td>102.532231</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>65</th>\n",
                            "      <td>RandomForest_r195_BAG_L1</td>\n",
                            "      <td>0.802370</td>\n",
                            "      <td>0.525326</td>\n",
                            "      <td>2.813130</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>66</th>\n",
                            "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
                            "      <td>0.801795</td>\n",
                            "      <td>0.304731</td>\n",
                            "      <td>142.996840</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>67</th>\n",
                            "      <td>ExtraTreesGini_BAG_L1</td>\n",
                            "      <td>0.801795</td>\n",
                            "      <td>0.569327</td>\n",
                            "      <td>1.384576</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>68</th>\n",
                            "      <td>RandomForestEntr_BAG_L1</td>\n",
                            "      <td>0.800989</td>\n",
                            "      <td>0.571245</td>\n",
                            "      <td>1.600018</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>69 rows × 4 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                        model  score_val  pred_time_val     fit_time\n",
                            "0             LightGBM_BAG_L3   0.840446      17.194179  1631.768937\n",
                            "1         WeightedEnsemble_L4   0.840446      17.197174  1632.407176\n",
                            "2        CatBoost_r177_BAG_L3   0.839756      17.186764  1652.045540\n",
                            "3             CatBoost_BAG_L3   0.839066      17.174221  1701.040648\n",
                            "4        LightGBM_r131_BAG_L3   0.838951      17.237628  1636.552284\n",
                            "..                        ...        ...            ...          ...\n",
                            "64      NeuralNetTorch_BAG_L1   0.802830       0.353503   102.532231\n",
                            "65   RandomForest_r195_BAG_L1   0.802370       0.525326     2.813130\n",
                            "66  NeuralNetTorch_r79_BAG_L1   0.801795       0.304731   142.996840\n",
                            "67      ExtraTreesGini_BAG_L1   0.801795       0.569327     1.384576\n",
                            "68    RandomForestEntr_BAG_L1   0.800989       0.571245     1.600018\n",
                            "\n",
                            "[69 rows x 4 columns]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "최고 모델: WeightedEnsemble_L4\n",
                        "내부 검증 정확도(Score_Val): 0.8404\n",
                        "Training Complete.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Starting AutoGluon Training...\")\n",
                "\n",
                "hyperparameters = {\n",
                "    'CAT': {'depth': 6},\n",
                "}\n",
                "\n",
                "predictor = TabularPredictor(\n",
                "    label=label,\n",
                "    eval_metric='accuracy',\n",
                "    path=MODEL_PATH,\n",
                "    problem_type='binary'\n",
                ").fit(\n",
                "    train_data=train_final,\n",
                "    presets='best_quality',\n",
                "    time_limit=3600, # 1 hour\n",
                "    num_bag_folds=8,\n",
                "    num_stack_levels=2,\n",
                "    hyperparameters=hyperparameters,\n",
                ")\n",
                "# 모델별 성적표(리더보드) 출력\n",
                "print(\"\\n=== [결과 리더보드] ===\")\n",
                "lb = predictor.leaderboard(extra_info=True)\n",
                "display(lb[['model', 'score_val', 'pred_time_val', 'fit_time']])\n",
                "\n",
                "# 최고 모델의 이름과 점수 가져오기\n",
                "# get_model_best() 대신 아래 두 가지 중 하나를 사용합니다.\n",
                "best_model_name = predictor.model_best \n",
                "best_score = lb.loc[lb['model'] == best_model_name, 'score_val'].values[0]\n",
                "\n",
                "print(f\"\\n최고 모델: {best_model_name}\")\n",
                "print(f\"내부 검증 정확도(Score_Val): {best_score:.4f}\")\n",
                "print(\"Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "모델을 따로 지정하지 않고, excluded_model_types=[] 설정을 통해 AutoGluon이 모든 모델을 사용해서 데이터의 특성에 맞춰 최적의 모델 조합을 스스로 선택하여 강력한 멀티레이어 스태킹(Multi-layer Stacking) 앙상블을 구축합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Verbosity: 2 (Standard Logging)\n",
                        "=================== System Info ===================\n",
                        "AutoGluon Version:  1.5.0\n",
                        "Python Version:     3.11.14\n",
                        "Operating System:   Windows\n",
                        "Platform Machine:   AMD64\n",
                        "Platform Version:   10.0.22631\n",
                        "CPU Count:          16\n",
                        "Pytorch Version:    2.9.1+cpu\n",
                        "CUDA Version:       CUDA is not available\n",
                        "Memory Avail:       9.04 GB / 31.72 GB (28.5%)\n",
                        "Disk Space Avail:   250.21 GB / 476.83 GB (52.5%)\n",
                        "===================================================\n",
                        "Presets specified: ['best_quality']\n",
                        "Using hyperparameters preset: hyperparameters='zeroshot'\n",
                        "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
                        "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=8, num_bag_sets=1\n",
                        "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
                        "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
                        "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
                        "\t\tContext path: \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\ag_models\\spaceship_autogluon_best_quality_v1\\ds_sub_fit\\sub_fit_ho\"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting AutoGluon Training...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Leaderboard on holdout data (DyStack):\n",
                        "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
                        "0         LightGBMXT_BAG_L2       0.814700   0.826712    accuracy        6.064746       4.227138  354.107949                 0.202710                0.237131          10.065766            2       True         13\n",
                        "1            XGBoost_BAG_L2       0.814700   0.825547    accuracy        6.180773       4.133321  349.135993                 0.318737                0.143314           5.093811            2       True         21\n",
                        "2   RandomForestGini_BAG_L3       0.811594   0.827747    accuracy        9.165972       7.527830  627.967878                 0.412521                0.514102           1.738129            3       True         27\n",
                        "3     ExtraTreesEntr_BAG_L2       0.810559   0.822053    accuracy        6.059507       4.395024  345.207662                 0.197471                0.405016           1.165480            2       True         19\n",
                        "4     ExtraTreesEntr_BAG_L3       0.810559   0.824123    accuracy        9.232517       7.524259  627.552525                 0.479066                0.510531           1.322776            3       True         31\n",
                        "5         LightGBMXT_BAG_L3       0.809524   0.832665    accuracy        9.112173       7.117588  630.478462                 0.358722                0.103860           4.248713            3       True         25\n",
                        "6     ExtraTreesGini_BAG_L3       0.809524   0.823735    accuracy        9.131366       7.395555  628.512111                 0.377916                0.381827           2.282362            3       True         30\n",
                        "7      LightGBMLarge_BAG_L1       0.808489   0.811699    accuracy        0.272472       0.283671   26.051488                 0.272472                0.283671          26.051488            1       True         11\n",
                        "8   RandomForestEntr_BAG_L3       0.808489   0.826064    accuracy        9.226051       7.453495  628.227562                 0.472600                0.439767           1.997813            3       True         28\n",
                        "9           LightGBM_BAG_L1       0.807453   0.816617    accuracy        0.124971       0.127975    2.740480                 0.124971                0.127975           2.740480            1       True          2\n",
                        "10   NeuralNetFastAI_BAG_L2       0.807453   0.823088    accuracy        6.213706       4.363306  376.654761                 0.351670                0.373298          32.612578            2       True         20\n",
                        "11           XGBoost_BAG_L1       0.806418   0.813770    accuracy        0.194532       0.164827    4.288794                 0.194532                0.164827           4.288794            1       True          9\n",
                        "12  RandomForestEntr_BAG_L1       0.806418   0.800828    accuracy        0.233473       0.440542    1.274182                 0.233473                0.440542           1.274182            1       True          4\n",
                        "13          CatBoost_BAG_L1       0.806418   0.820370    accuracy        0.830353       0.075033  120.621145                 0.830353                0.075033         120.621145            1       True          5\n",
                        "14    NeuralNetTorch_BAG_L2       0.806418   0.818817    accuracy        6.262552       4.238878  392.673108                 0.400516                0.248870          48.630925            2       True         22\n",
                        "15    ExtraTreesEntr_BAG_L1       0.805383   0.798758    accuracy        0.369635       0.772457    2.057302                 0.369635                0.772457           2.057302            1       True          7\n",
                        "16  RandomForestGini_BAG_L2       0.805383   0.823864    accuracy        6.097318       4.431191  346.592712                 0.235282                0.441184           2.550529            2       True         15\n",
                        "17          CatBoost_BAG_L3       0.805383   0.834735    accuracy        9.013730       7.159108  715.051434                 0.260279                0.145380          88.821685            3       True         29\n",
                        "18      WeightedEnsemble_L4       0.805383   0.834735    accuracy        9.037001       7.163709  715.875487                 0.023271                0.004601           0.824053            4       True         33\n",
                        "19  RandomForestGini_BAG_L1       0.804348   0.801217    accuracy        0.257841       0.618881    1.572873                 0.257841                0.618881           1.572873            1       True          3\n",
                        "20        LightGBMXT_BAG_L1       0.804348   0.823735    accuracy        0.713244       0.156485    2.873333                 0.713244                0.156485           2.873333            1       True          1\n",
                        "21      WeightedEnsemble_L2       0.804348   0.823735    accuracy        0.717818       0.158471    3.176868                 0.004574                0.001986           0.303535            2       True         12\n",
                        "22          LightGBM_BAG_L3       0.803313   0.833312    accuracy        9.146055       7.096544  630.272056                 0.392604                0.082816           4.042307            3       True         26\n",
                        "23   NeuralNetFastAI_BAG_L3       0.803313   0.830206    accuracy        9.599985       7.734969  675.605083                 0.846534                0.721241          49.375334            3       True         32\n",
                        "24          CatBoost_BAG_L2       0.802277   0.829429    accuracy        5.929753       4.063547  512.985802                 0.067717                0.073539         168.943620            2       True         17\n",
                        "25          LightGBM_BAG_L2       0.802277   0.828265    accuracy        5.957479       4.071227  349.814499                 0.095443                0.081220           5.772317            2       True         14\n",
                        "26      WeightedEnsemble_L3       0.802277   0.829429    accuracy        5.966840       4.065103  513.390580                 0.037087                0.001556           0.404777            3       True         24\n",
                        "27  RandomForestEntr_BAG_L2       0.802277   0.823994    accuracy        6.034230       4.492789  346.613653                 0.172194                0.502781           2.571470            2       True         16\n",
                        "28    ExtraTreesGini_BAG_L2       0.801242   0.822311    accuracy        6.239459       4.430892  345.428495                 0.377423                0.440884           1.386312            2       True         18\n",
                        "29     LightGBMLarge_BAG_L2       0.801242   0.826064    accuracy        6.334286       4.066490  347.436941                 0.472250                0.076482           3.394759            2       True         23\n",
                        "30    ExtraTreesGini_BAG_L1       0.800207   0.802381    accuracy        0.439931       0.664648    3.618783                 0.439931                0.664648           3.618783            1       True          6\n",
                        "31   NeuralNetFastAI_BAG_L1       0.796066   0.818429    accuracy        2.125569       0.426084   34.774757                 2.125569                0.426084          34.774757            1       True          8\n",
                        "32    NeuralNetTorch_BAG_L1       0.790890   0.803417    accuracy        0.300013       0.259405  144.169044                 0.300013                0.259405         144.169044            1       True         10\n",
                        "\t2\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
                        "\t946s\t = DyStack   runtime |\t2654s\t = Remaining runtime\n",
                        "Starting main fit with num_stack_levels=2.\n",
                        "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=2)`\n",
                        "Beginning AutoGluon training ... Time limit = 2654s\n",
                        "AutoGluon will save models to \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\ag_models\\spaceship_autogluon_best_quality_v1\"\n",
                        "Train Data Rows:    8693\n",
                        "Train Data Columns: 17\n",
                        "Label Column:       Transported\n",
                        "Problem Type:       binary\n",
                        "Preprocessing data ...\n",
                        "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
                        "Using Feature Generators to preprocess the data ...\n",
                        "Fitting AutoMLPipelineFeatureGenerator...\n",
                        "\tAvailable Memory:                    8395.32 MB\n",
                        "\tTrain Data (Original)  Memory Usage: 3.24 MB (0.0% of available memory)\n",
                        "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
                        "\tStage 1 Generators:\n",
                        "\t\tFitting AsTypeFeatureGenerator...\n",
                        "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
                        "\tStage 2 Generators:\n",
                        "\t\tFitting FillNaFeatureGenerator...\n",
                        "\tStage 3 Generators:\n",
                        "\t\tFitting IdentityFeatureGenerator...\n",
                        "\t\tFitting CategoryFeatureGenerator...\n",
                        "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
                        "\tStage 4 Generators:\n",
                        "\t\tFitting DropUniqueFeatureGenerator...\n",
                        "\tStage 5 Generators:\n",
                        "\t\tFitting DropDuplicatesFeatureGenerator...\n",
                        "\tTypes of features in original data (raw dtype, special dtypes):\n",
                        "\t\t('bool', [])   : 2 | ['CryoSleep', 'VIP']\n",
                        "\t\t('float', [])  : 9 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\t\t('int', [])    : 1 | ['GroupSize']\n",
                        "\t\t('object', []) : 5 | ['HomePlanet', 'Destination', 'AgeGroup', 'Deck', 'Side']\n",
                        "\tTypes of features in processed data (raw dtype, special dtypes):\n",
                        "\t\t('category', [])  : 5 | ['HomePlanet', 'Destination', 'AgeGroup', 'Deck', 'Side']\n",
                        "\t\t('float', [])     : 9 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\t\t('int', [])       : 1 | ['GroupSize']\n",
                        "\t\t('int', ['bool']) : 2 | ['CryoSleep', 'VIP']\n",
                        "\t0.2s = Fit runtime\n",
                        "\t17 features in original data used to generate 17 features in processed data.\n",
                        "\tTrain Data (Processed) Memory Usage: 0.72 MB (0.0% of available memory)\n",
                        "Data preprocessing and feature engineering runtime = 0.27s ...\n",
                        "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
                        "\tTo change this, specify the eval_metric parameter of Predictor()\n",
                        "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
                        "User-specified model hyperparameters to be fit:\n",
                        "{\n",
                        "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
                        "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
                        "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
                        "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
                        "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
                        "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
                        "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
                        "}\n",
                        "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
                        "Excluded models: [] (Specified by `excluded_model_types`)\n",
                        "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1179.14s of the 2653.70s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.27%)\n",
                        "\t0.8201\t = Validation score   (accuracy)\n",
                        "\t7.87s\t = Training   runtime\n",
                        "\t0.37s\t = Validation runtime\n",
                        "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1161.13s of the 2635.69s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.29%)\n",
                        "\t0.8171\t = Validation score   (accuracy)\n",
                        "\t6.39s\t = Training   runtime\n",
                        "\t0.24s\t = Validation runtime\n",
                        "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1144.58s of the 2619.14s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/7.2 GB\n",
                        "\t0.8039\t = Validation score   (accuracy)\n",
                        "\t2.55s\t = Training   runtime\n",
                        "\t0.63s\t = Validation runtime\n",
                        "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1141.17s of the 2615.74s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/7.9 GB\n",
                        "\t0.801\t = Validation score   (accuracy)\n",
                        "\t2.04s\t = Training   runtime\n",
                        "\t0.55s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1138.41s of the 2612.98s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=5.00%)\n",
                        "\t0.8227\t = Validation score   (accuracy)\n",
                        "\t111.41s\t = Training   runtime\n",
                        "\t0.12s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1017.70s of the 2492.27s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/7.8 GB\n",
                        "\t0.8018\t = Validation score   (accuracy)\n",
                        "\t1.87s\t = Training   runtime\n",
                        "\t0.72s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1014.86s of the 2489.43s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/7.9 GB\n",
                        "\t0.804\t = Validation score   (accuracy)\n",
                        "\t2.06s\t = Training   runtime\n",
                        "\t0.76s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1011.82s of the 2486.38s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.10%)\n",
                        "\t0.8202\t = Validation score   (accuracy)\n",
                        "\t54.76s\t = Training   runtime\n",
                        "\t0.59s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L1 ... Training model for up to 946.39s of the 2420.96s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
                        "\t0.8186\t = Validation score   (accuracy)\n",
                        "\t8.02s\t = Training   runtime\n",
                        "\t1.42s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 927.92s of the 2402.49s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.06%)\n",
                        "\t0.8028\t = Validation score   (accuracy)\n",
                        "\t130.76s\t = Training   runtime\n",
                        "\t0.34s\t = Validation runtime\n",
                        "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 786.67s of the 2261.24s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.02%)\n",
                        "\t0.813\t = Validation score   (accuracy)\n",
                        "\t21.48s\t = Training   runtime\n",
                        "\t0.16s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 754.88s of the 2229.44s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.50%)\n",
                        "\t0.8242\t = Validation score   (accuracy)\n",
                        "\t34.45s\t = Training   runtime\n",
                        "\t1.79s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 712.80s of the 2187.37s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.8018\t = Validation score   (accuracy)\n",
                        "\t204.29s\t = Training   runtime\n",
                        "\t0.3s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 503.84s of the 1978.40s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.38%)\n",
                        "\t0.8181\t = Validation score   (accuracy)\n",
                        "\t7.47s\t = Training   runtime\n",
                        "\t0.44s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 491.14s of the 1965.70s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.09%)\n",
                        "\t0.8173\t = Validation score   (accuracy)\n",
                        "\t112.94s\t = Training   runtime\n",
                        "\t0.83s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 372.73s of the 1847.30s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=5.50%)\n",
                        "\t0.822\t = Validation score   (accuracy)\n",
                        "\t160.99s\t = Training   runtime\n",
                        "\t0.54s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 201.26s of the 1675.83s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.16%)\n",
                        "\t0.8143\t = Validation score   (accuracy)\n",
                        "\t8.51s\t = Training   runtime\n",
                        "\t0.62s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 182.59s of the 1657.15s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.06%)\n",
                        "\t0.804\t = Validation score   (accuracy)\n",
                        "\t153.29s\t = Training   runtime\n",
                        "\t0.57s\t = Validation runtime\n",
                        "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 19.04s of the 1493.60s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.91%)\n",
                        "\t0.8131\t = Validation score   (accuracy)\n",
                        "\t15.57s\t = Training   runtime\n",
                        "\t1.45s\t = Validation runtime\n",
                        "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1466.31s of remaining time.\n",
                        "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/9.3 GB\n",
                        "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 1.0}\n",
                        "\t0.8242\t = Validation score   (accuracy)\n",
                        "\t0.44s\t = Training   runtime\n",
                        "\t0.0s\t = Validation runtime\n",
                        "Excluded models: [] (Specified by `excluded_model_types`)\n",
                        "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 976.96s of the 1465.72s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.31%)\n",
                        "\t0.8285\t = Validation score   (accuracy)\n",
                        "\t7.76s\t = Training   runtime\n",
                        "\t0.23s\t = Validation runtime\n",
                        "Fitting model: LightGBM_BAG_L2 ... Training model for up to 960.49s of the 1449.25s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.32%)\n",
                        "\t0.8323\t = Validation score   (accuracy)\n",
                        "\t5.11s\t = Training   runtime\n",
                        "\t0.11s\t = Validation runtime\n",
                        "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 948.67s of the 1437.42s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/8.9 GB\n",
                        "\t0.8261\t = Validation score   (accuracy)\n",
                        "\t2.35s\t = Training   runtime\n",
                        "\t0.51s\t = Validation runtime\n",
                        "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 945.68s of the 1434.44s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.3 GB\n",
                        "\t0.826\t = Validation score   (accuracy)\n",
                        "\t2.77s\t = Training   runtime\n",
                        "\t0.56s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L2 ... Training model for up to 942.25s of the 1431.01s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.47%)\n",
                        "\t0.8296\t = Validation score   (accuracy)\n",
                        "\t96.0s\t = Training   runtime\n",
                        "\t0.1s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 839.36s of the 1328.12s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.9 GB\n",
                        "\t0.8208\t = Validation score   (accuracy)\n",
                        "\t1.38s\t = Training   runtime\n",
                        "\t0.57s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 837.28s of the 1326.03s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/10.1 GB\n",
                        "\t0.8228\t = Validation score   (accuracy)\n",
                        "\t1.2s\t = Training   runtime\n",
                        "\t0.52s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 835.44s of the 1324.20s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.15%)\n",
                        "\t0.8238\t = Validation score   (accuracy)\n",
                        "\t33.84s\t = Training   runtime\n",
                        "\t0.37s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L2 ... Training model for up to 796.86s of the 1285.62s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.36%)\n",
                        "\t0.8301\t = Validation score   (accuracy)\n",
                        "\t7.0s\t = Training   runtime\n",
                        "\t1.03s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 783.00s of the 1271.76s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.08%)\n",
                        "\t0.8234\t = Validation score   (accuracy)\n",
                        "\t206.55s\t = Training   runtime\n",
                        "\t1.38s\t = Validation runtime\n",
                        "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 569.89s of the 1058.65s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.80%)\n",
                        "\t0.8322\t = Validation score   (accuracy)\n",
                        "\t47.91s\t = Training   runtime\n",
                        "\t0.09s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 516.86s of the 1005.62s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.46%)\n",
                        "\t0.8318\t = Validation score   (accuracy)\n",
                        "\t24.51s\t = Training   runtime\n",
                        "\t0.07s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 488.36s of the 977.12s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n"
                    ]
                }
            ],
            "source": [
                "print(\"Starting AutoGluon Training...\")\n",
                "\n",
                "predictor = TabularPredictor(\n",
                "    label=label,\n",
                "    eval_metric='accuracy',\n",
                "    path='ag_models/spaceship_autogluon_best_quality_v1',\n",
                "    problem_type='binary'\n",
                ").fit(\n",
                "    train_data=train_final,\n",
                "    presets='best_quality',      # 고품질 앙상블 활성화\n",
                "    time_limit=3600,             # 1시간 동안 충분히 모델들을 섞음\n",
                "    num_bag_folds=8,             # 안정적인 점수를 위한 8겹 배깅\n",
                "    num_stack_levels=2,          # 모델들의 예측치를 다시 학습하는 2단계 스태킹\n",
                "    excluded_model_types=[], # 모든 모델 사용\n",
                ")\n",
                "\n",
                "# 모델별 성적표(리더보드) 출력\n",
                "print(\"\\n=== [결과 리더보드] ===\")\n",
                "lb = predictor.leaderboard(extra_info=True)\n",
                "display(lb[['model', 'score_val', 'pred_time_val', 'fit_time']])\n",
                "\n",
                "# 최고 모델의 이름과 점수 가져오기\n",
                "# get_model_best() 대신 아래 두 가지 중 하나를 사용합니다.\n",
                "best_model_name = predictor.model_best \n",
                "best_score = lb.loc[lb['model'] == best_model_name, 'score_val'].values[0]\n",
                "\n",
                "print(f\"\\n최고 모델: {best_model_name}\")\n",
                "print(f\"내부 검증 정확도(Score_Val): {best_score:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 모델 학습 결과 요약 및 성능 평가"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "*** Summary of fit() ***\n",
                        "Estimated performance of each model:\n",
                        "                 model  score_val eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
                        "0      CatBoost_BAG_L1   0.822731    accuracy       0.077698  57.885597                0.077698          57.885597            1       True          1\n",
                        "1  WeightedEnsemble_L2   0.822731    accuracy       0.080682  57.904061                0.002984           0.018465            2       True          2\n",
                        "Number of models trained: 2\n",
                        "Types of models trained:\n",
                        "{'StackerEnsembleModel_CatBoost', 'WeightedEnsembleModel'}\n",
                        "Bagging used: True  (with 8 folds)\n",
                        "Multi-layer stack-ensembling used: False \n",
                        "Feature Metadata (Processed):\n",
                        "(raw dtype, special dtypes):\n",
                        "('category', [])  : 5 | ['HomePlanet', 'Destination', 'AgeGroup', 'Deck', 'Side']\n",
                        "('float', [])     : 9 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "('int', [])       : 1 | ['GroupSize']\n",
                        "('int', ['bool']) : 2 | ['CryoSleep', 'VIP']\n",
                        "*** End of fit() summary ***\n",
                        "{'model_types': {'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'CatBoost_BAG_L1': 0.822730932934545, 'WeightedEnsemble_L2': 0.822730932934545}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'CatBoost_BAG_L1': ['CatBoost_BAG_L1'], 'WeightedEnsemble_L2': ['WeightedEnsemble_L2']}, 'model_fit_times': {'CatBoost_BAG_L1': 57.88559651374817, 'WeightedEnsemble_L2': 0.01846456527709961}, 'model_pred_times': {'CatBoost_BAG_L1': 0.07769775390625, 'WeightedEnsemble_L2': 0.002984285354614258}, 'num_bag_folds': 8, 'max_stack_level': 2, 'num_classes': 2, 'model_hyperparams': {'CatBoost_BAG_L1': {'use_orig_features': True, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'stratify': 'auto', 'bin': 'auto', 'n_bins': None, 'vary_seed_across_folds': False, 'model_random_seed': 0}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'valid_stacker': True, 'max_base_models': 0, 'max_base_models_per_type': 'auto', 'save_bag_folds': True, 'stratify': 'auto', 'bin': 'auto', 'n_bins': None, 'vary_seed_across_folds': False, 'model_random_seed': 0}}, 'leaderboard':                  model  score_val eval_metric  pred_time_val   fit_time  \\\n",
                        "0      CatBoost_BAG_L1   0.822731    accuracy       0.077698  57.885597   \n",
                        "1  WeightedEnsemble_L2   0.822731    accuracy       0.080682  57.904061   \n",
                        "\n",
                        "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
                        "0                0.077698          57.885597            1       True   \n",
                        "1                0.002984           0.018465            2       True   \n",
                        "\n",
                        "   fit_order  \n",
                        "0          1  \n",
                        "1          2  }\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\autogluon\\core\\utils\\plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
                        "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
                    ]
                }
            ],
            "source": [
                "print(predictor.fit_summary())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 예측 및 제출 파일 생성\n",
                "학습된 모델을 사용하여 최종 예측을 수행하고, 캐글 제출 양식에 맞는 submission.csv 파일을 생성합니다"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "WeightedEnsemble_L2 : 0.8227점, 케글 점수 : 0.81038점"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating predictions...\n",
                        "Submission saved successfully to submission/submission_optimized.csv\n",
                        "\n",
                        "=== [제출 파일 상단 5행 확인] ===\n",
                        "  PassengerId  Transported\n",
                        "0     0013_01         True\n",
                        "1     0018_01        False\n",
                        "2     0019_01         True\n",
                        "3     0021_01         True\n",
                        "4     0023_01        False\n"
                    ]
                }
            ],
            "source": [
                "print(\"Generating predictions...\")\n",
                "# 예측 수행\n",
                "y_pred = predictor.predict(test_final)\n",
                "\n",
                "# 제출용 데이터프레임 생성 (인덱스 꼬임 방지를 위해 .values 사용)\n",
                "submission = pd.DataFrame({\n",
                "    'PassengerId': test_df['PassengerId'].values, \n",
                "    'Transported': y_pred.values \n",
                "})\n",
                "\n",
                "# 데이터 타입 보정 (True/False 형태인지 확인)\n",
                "submission['Transported'] = submission['Transported'].astype(bool)\n",
                "\n",
                "# 저장 폴더 확인 및 저장\n",
                "if not os.path.exists('submission'):\n",
                "    os.makedirs('submission')\n",
                "\n",
                "submission.to_csv(SUBMISSION_PATH, index=False)\n",
                "\n",
                "print(f\"Submission saved successfully to {SUBMISSION_PATH}\")\n",
                "print(\"\\n=== [제출 파일 상단 5행 확인] ===\")\n",
                "print(submission.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

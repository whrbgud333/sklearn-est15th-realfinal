{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spaceship Titanic: AutoGluon 최적화 모델\n",
                "\n",
                "이 노트북은 `Spaceship_3_수정후.ipynb`의 피처 엔지니어링 과정을 복제하고, AutoGluon을 사용하여 최적의 모델을 찾는 것을 목표로 합니다.\n",
                "\n",
                "## 주요 단계\n",
                "1. 데이터 로드\n",
                "2. 결측치 처리 및 파생 변수 생성 (기존 노트북 로직 계승)\n",
                "3. 데이터 인코딩 및 스케일링\n",
                "4. AutoGluon을 이용한 모델 학습 (`best_quality` 프리셋 적용)\n",
                "5. 제출 파일 생성"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from autogluon.tabular import TabularPredictor\n",
                "\n",
                "# 경고 무시\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 데이터 로드"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train shape: (8693, 14)\n",
                        "Test shape: (4277, 13)\n"
                    ]
                }
            ],
            "source": [
                "train_df = pd.read_csv('train.csv')\n",
                "test_df = pd.read_csv('test.csv')\n",
                "\n",
                "print(f\"Train shape: {train_df.shape}\")\n",
                "print(f\"Test shape: {test_df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 데이터 전처리 , 특성 엔지니어링\n",
                "\n",
                "`Spaceship_3_수정후.ipynb`에서 수행한 전처리 과정을 동일하게 적용합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 처리를 위해 데이터 합치기\n",
                "all_data = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
                "\n",
                "# 1. Group, GroupSize, FamilyId, FamilySize 생성\n",
                "all_data['Group'] = all_data['PassengerId'].apply(lambda x: x.split('_')[0])\n",
                "all_data['GroupSize'] = all_data.groupby('Group')['Group'].transform('count')\n",
                "\n",
                "# 2. Cabin 분리 (Deck, Num, Side)\n",
                "all_data[['Deck', 'Num', 'Side']] = all_data['Cabin'].str.split('/', expand=True)\n",
                "\n",
                "# 3. Surname 생성\n",
                "all_data['Surname'] = all_data['Name'].str.split().str[-1]\n",
                "\n",
                "# 4. FamilyId, FamilySize 생성\n",
                "all_data['FamilyId'] = all_data['Surname'] + all_data['Group']\n",
                "all_data['FamilySize'] = all_data.groupby('FamilyId')['FamilyId'].transform('count')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 결측치 처리\n",
                "\n",
                "각 컬럼별로 논리적인 규칙을 적용하여 결측치를 채웁니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 지출 관련 컬럼\n",
                "spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
                "\n",
                "# TotalSpending 결측치 처리 (0으로 채움)\n",
                "all_data[spending_cols] = all_data[spending_cols].fillna(0)\n",
                "all_data['TotalSpending'] = all_data[spending_cols].sum(axis=1)\n",
                "\n",
                "# 2CryoSleep 결측치 처리\n",
                "# 지출이 있으면 깨어 있음(False), 지출이 없으면 동면 중(True)일 확률 높음\n",
                "all_data.loc[(all_data['CryoSleep'].isna()) & (all_data['TotalSpending'] > 0), 'CryoSleep'] = False\n",
                "all_data.loc[(all_data['CryoSleep'].isna()) & (all_data['TotalSpending'] == 0), 'CryoSleep'] = True\n",
                "\n",
                "# Age 결측치 처리 (중앙값)\n",
                "age_median = all_data['Age'].median()\n",
                "all_data['Age'] = all_data['Age'].fillna(age_median)\n",
                "\n",
                "# AgeGroup 생성\n",
                "def update_age_group(age):\n",
                "    if age <= 4: return 'Baby'\n",
                "    elif age <= 12: return 'Child'\n",
                "    elif age <= 19: return 'Teenager'\n",
                "    elif age <= 40: return 'Adult'\n",
                "    elif age <= 60: return 'Middle Aged'\n",
                "    else: return 'Senior'\n",
                "\n",
                "all_data['AgeGroup'] = all_data['Age'].apply(update_age_group)\n",
                "\n",
                "# VIP 결측치 처리\n",
                "# 지출이 0원이거나 미성년자, 혹은 지구 출신이면 VIP가 아닐 확률이 높음\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['TotalSpending'] == 0), 'VIP'] = False\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['Age'] <= 19), 'VIP'] = False\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['HomePlanet'] == 'Earth'), 'VIP'] = False\n",
                "all_data['VIP'] = all_data['VIP'].fillna(False)\n",
                "\n",
                "# Destination 결측치 처리 (최빈값)\n",
                "dest_mode = all_data['Destination'].mode()[0]\n",
                "all_data['Destination'] = all_data['Destination'].fillna(dest_mode)\n",
                "\n",
                "# HomePlanet 결측치 처리\n",
                "# 같은 그룹이나 성씨를 공유하는 승객의 정보를 활용\n",
                "all_data['HomePlanet'] = all_data.groupby('Group')['HomePlanet'].ffill().bfill()\n",
                "home_map = all_data.dropna(subset=['HomePlanet']).groupby('Surname')['HomePlanet'].apply(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
                "all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['Surname'].map(home_map))\n",
                "all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['HomePlanet'].mode()[0])\n",
                "\n",
                "# Cabin 결측치 처리\n",
                "# 같은 그룹의 Deck, Side, Num 정보 공유\n",
                "all_data['Deck'] = all_data.groupby('Group')['Deck'].ffill().bfill()\n",
                "all_data['Side'] = all_data.groupby('Group')['Side'].ffill().bfill()\n",
                "all_data['Num'] = pd.to_numeric(all_data['Num'], errors='coerce')\n",
                "all_data['Num'] = all_data.groupby('Group')['Num'].ffill().bfill()\n",
                "\n",
                "# 남은 결측치는 최빈값 또는 평균으로 채움 (AutoGluon은 결측치를 잘 처리하지만, 명시적 처리가 도움될 수 있음)\n",
                "all_data['Deck'] = all_data['Deck'].fillna(all_data['Deck'].mode()[0])\n",
                "all_data['Side'] = all_data['Side'].fillna(all_data['Side'].mode()[0])\n",
                "all_data['Num'] = all_data['Num'].fillna(all_data['Num'].median())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 파생 변수 생성 및 정리\n",
                "\n",
                "모델 학습에 도움이 될 추가 변수를 생성하고, 불필요한 데이터를 정리합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 추가 파생 변수\n",
                "all_data['IsSleepZero'] = (all_data['TotalSpending'] == 0).astype(int)\n",
                "all_data['IsAlone'] = ((all_data['GroupSize'] == 1) & (all_data['FamilySize'] == 1)).astype(int)\n",
                "all_data['IsVIPDeck'] = all_data['Deck'].isin(['B', 'C', 'T']).astype(int)\n",
                "\n",
                "# Boolean 타입 정수형 변환\n",
                "all_data['CryoSleep'] = all_data['CryoSleep'].astype(int)\n",
                "all_data['VIP'] = all_data['VIP'].astype(int)\n",
                "\n",
                "# 데이터 정제\n",
                "# 동면 중인 승객의 지출액은 0원이어야 함 (논리적 오류 수정)\n",
                "all_data.loc[all_data['CryoSleep'] == 1, spending_cols] = 0\n",
                "all_data['TotalSpending'] = all_data[spending_cols].sum(axis=1)\n",
                "\n",
                "# 불필요한 컬럼 삭제\n",
                "drop_cols = ['PassengerId', 'Name', 'Cabin', 'Surname', 'Group', 'FamilyId', 'AgeGroup', 'FamilySize', 'GroupSize']\n",
                "all_data = all_data.drop(columns=drop_cols)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 인코딩 및 스케일링\n",
                "\n",
                "범주형 변수는 One-Hot Encoding을, 수치형 변수는 Standard Scaling을 적용합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "전처리 완료!\n",
                        "Train processed shape: (8693, 26)\n",
                        "Test processed shape: (4277, 26)\n"
                    ]
                }
            ],
            "source": [
                "# 범주형 및 수치형 컬럼 정의\n",
                "cat_cols = ['HomePlanet', 'Destination', 'Deck', 'Side']\n",
                "num_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpending', 'Num']\n",
                "\n",
                "# One-Hot Encoding\n",
                "all_data = pd.get_dummies(all_data, columns=cat_cols, drop_first=True)\n",
                "\n",
                "# Standard Scaling\n",
                "scaler = StandardScaler()\n",
                "all_data[num_cols] = scaler.fit_transform(all_data[num_cols])\n",
                "\n",
                "# 데이터 분리 (Train / Test)\n",
                "train_processed = all_data[:len(train_df)]\n",
                "test_processed = all_data[len(train_df):]\n",
                "\n",
                "# 타겟 변수 다시 추가 (Train)\n",
                "train_processed['Transported'] = train_df['Transported'].values\n",
                "\n",
                "print(\"전처리 완료!\")\n",
                "print(f\"Train processed shape: {train_processed.shape}\")\n",
                "print(f\"Test processed shape: {test_processed.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. AutoGluon 모델 학습\n",
                "\n",
                "`best_quality` 프리셋을 사용하여 최적의 모델을 찾습니다. 시간 제한은 1시간(3600초)으로 설정합니다."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "30b0fd72",
            "metadata": {},
            "source": [
                "excluded_model_types=[]으로 모든 모델 사용, 최고 모델은 NeuralNetFastAI_BAG_L2로 0.8246점이 나왔습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Verbosity: 2 (Standard Logging)\n",
                        "=================== System Info ===================\n",
                        "AutoGluon Version:  1.5.0\n",
                        "Python Version:     3.11.14\n",
                        "Operating System:   Windows\n",
                        "Platform Machine:   AMD64\n",
                        "Platform Version:   10.0.22631\n",
                        "CPU Count:          16\n",
                        "Pytorch Version:    2.9.1+cpu\n",
                        "CUDA Version:       CUDA is not available\n",
                        "Memory Avail:       5.88 GB / 31.72 GB (18.5%)\n",
                        "Disk Space Avail:   252.97 GB / 476.83 GB (53.1%)\n",
                        "===================================================\n",
                        "Presets specified: ['best_quality']\n",
                        "Using hyperparameters preset: hyperparameters='zeroshot'\n",
                        "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
                        "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=8, num_bag_sets=1\n",
                        "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
                        "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
                        "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
                        "\t\tContext path: \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\ag_models\\spaceship_autogluon_best_quality_v3\\ds_sub_fit\\sub_fit_ho\"\n",
                        "Leaderboard on holdout data (DyStack):\n",
                        "                        model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
                        "0      NeuralNetFastAI_BAG_L2       0.819876   0.824641    accuracy        5.648782       3.272587  364.813972                 0.238963                0.385875          46.348440            2       True         23\n",
                        "1           LightGBMXT_BAG_L1       0.817805   0.818041    accuracy        0.557915       0.078357    3.202797                 0.557915                0.078357           3.202797            1       True          1\n",
                        "2       ExtraTreesEntr_BAG_L2       0.815735   0.822829    accuracy        5.630558       3.740172  320.040071                 0.220739                0.853461           1.574539            2       True         22\n",
                        "3        LightGBMLarge_BAG_L1       0.814700   0.811570    accuracy        0.068401       0.087360    8.744136                 0.068401                0.087360           8.744136            1       True         11\n",
                        "4     RandomForestGini_BAG_L1       0.814700   0.802770    accuracy        0.270233       0.375098    1.550593                 0.270233                0.375098           1.550593            1       True          3\n",
                        "5       NeuralNetTorch_BAG_L2       0.814700   0.821923    accuracy        5.700337       3.085871  425.611919                 0.290518                0.199159         107.146387            2       True         25\n",
                        "6        CatBoost_r177_BAG_L2       0.813665   0.828653    accuracy        5.484001       2.935166  327.668041                 0.074182                0.048455           9.202509            2       True         27\n",
                        "7     RandomForestGini_BAG_L3       0.813665   0.830076    accuracy        7.758536       7.564529  576.349385                 0.198301                0.375707           2.247538            3       True         32\n",
                        "8             LightGBM_BAG_L1       0.812629   0.815193    accuracy        0.072814       0.060622    2.599480                 0.072814                0.060622           2.599480            1       True          2\n",
                        "9              XGBoost_BAG_L1       0.812629   0.815193    accuracy        0.107319       0.062744    2.118663                 0.107319                0.062744           2.118663            1       True          9\n",
                        "10            CatBoost_BAG_L2       0.812629   0.831500    accuracy        5.449607       2.977811  341.074691                 0.039788                0.091100          22.609159            2       True         20\n",
                        "11             XGBoost_BAG_L3       0.812629   0.835382    accuracy        7.669710       7.297009  580.728467                 0.109476                0.108187           6.626621            3       True         38\n",
                        "12      NeuralNetTorch_BAG_L3       0.812629   0.830335    accuracy        7.702696       7.524015  609.446276                 0.142461                0.335193          35.344429            3       True         39\n",
                        "13    RandomForestEntr_BAG_L1       0.811594   0.800958    accuracy        0.208809       0.416761    1.123890                 0.208809                0.416761           1.123890            1       True          4\n",
                        "14       CatBoost_r177_BAG_L1       0.810559   0.821017    accuracy        0.034621       0.029508   10.454502                 0.034621                0.029508          10.454502            1       True         12\n",
                        "15            LightGBM_BAG_L3       0.810559   0.836677    accuracy        7.599220       7.222264  578.036194                 0.038985                0.033441           3.934347            3       True         31\n",
                        "16    RandomForestEntr_BAG_L3       0.810559   0.830723    accuracy        7.707460       7.568029  576.167417                 0.147225                0.379207           2.065570            3       True         33\n",
                        "17            CatBoost_BAG_L1       0.809524   0.822441    accuracy        1.140966       0.053327    8.408833                 1.140966                0.053327           8.408833            1       True          5\n",
                        "18        WeightedEnsemble_L2       0.809524   0.822441    accuracy        1.142992       0.054838    8.848237                 0.002026                0.001511           0.439404            2       True         15\n",
                        "19      ExtraTreesGini_BAG_L2       0.809524   0.823476    accuracy        5.594125       3.411066  320.530891                 0.184306                0.524355           2.065359            2       True         21\n",
                        "20  NeuralNetTorch_r79_BAG_L2       0.809524   0.823217    accuracy        5.634426       3.304658  346.339946                 0.224607                0.417947          27.874414            2       True         28\n",
                        "21          LightGBMXT_BAG_L3       0.809524   0.833700    accuracy        7.604555       7.231169  577.039293                 0.044320                0.042347           2.937446            3       True         30\n",
                        "22          LightGBMXT_BAG_L2       0.808489   0.829041    accuracy        5.478998       3.078717  326.275473                 0.069179                0.192006           7.809942            2       True         16\n",
                        "23            CatBoost_BAG_L3       0.808489   0.837453    accuracy        7.594328       7.218081  587.898749                 0.034093                0.029259          13.796902            3       True         34\n",
                        "24      ExtraTreesGini_BAG_L3       0.808489   0.823347    accuracy        7.753637       7.762402  575.511792                 0.193403                0.573580           1.409945            3       True         35\n",
                        "25      ExtraTreesEntr_BAG_L3       0.808489   0.823088    accuracy        7.754126       7.841649  575.455138                 0.193891                0.652827           1.353291            3       True         36\n",
                        "26            LightGBM_BAG_L2       0.807453   0.832147    accuracy        5.435330       2.970972  323.813776                 0.025511                0.084261           5.348245            2       True         17\n",
                        "27        WeightedEnsemble_L3       0.807453   0.832147    accuracy        5.437831       2.972977  324.348375                 0.002501                0.002005           0.534599            3       True         29\n",
                        "28        WeightedEnsemble_L4       0.807453   0.837971    accuracy        7.636812       7.254125  592.678874                 0.003499                0.002603           0.845778            4       True         40\n",
                        "29      ExtraTreesGini_BAG_L1       0.806418   0.797334    accuracy        0.533853       0.539283    1.521462                 0.533853                0.539283           1.521462            1       True          6\n",
                        "30    RandomForestEntr_BAG_L2       0.806418   0.825417    accuracy        5.546911       3.555401  321.260009                 0.137092                0.668690           2.794477            2       True         19\n",
                        "31    RandomForestGini_BAG_L2       0.806418   0.824253    accuracy        5.566874       3.383501  321.448837                 0.157055                0.496790           2.983305            2       True         18\n",
                        "32  NeuralNetTorch_r79_BAG_L1       0.805383   0.804711    accuracy        0.129873       0.212816  129.574023                 0.129873                0.212816         129.574023            1       True         13\n",
                        "33      ExtraTreesEntr_BAG_L1       0.805383   0.796428    accuracy        0.357336       0.514245    1.132858                 0.357336                0.514245           1.132858            1       True          7\n",
                        "34       LightGBMLarge_BAG_L2       0.805383   0.828265    accuracy        5.707922       3.090555  330.281713                 0.298103                0.203844          11.816181            2       True         26\n",
                        "35     NeuralNetFastAI_BAG_L3       0.805383   0.829818    accuracy        7.764399       7.564202  623.950223                 0.204164                0.375380          49.848377            3       True         37\n",
                        "36       LightGBM_r131_BAG_L1       0.803313   0.815841    accuracy        0.076738       0.143417    6.033551                 0.076738                0.143417           6.033551            1       True         14\n",
                        "37     NeuralNetFastAI_BAG_L1       0.800207   0.814158    accuracy        1.770846       0.187851   45.668524                 1.770846                0.187851          45.668524            1       True          8\n",
                        "38      NeuralNetTorch_BAG_L1       0.798137   0.804840    accuracy        0.148495       0.212682  105.076356                 0.148495                0.212682         105.076356            1       True         10\n",
                        "39             XGBoost_BAG_L2       0.796066   0.828394    accuracy        5.600190       3.022879  326.528888                 0.190371                0.136168           8.063356            2       True         24\n",
                        "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
                        "\t927s\t = DyStack   runtime |\t2673s\t = Remaining runtime\n",
                        "Starting main fit with num_stack_levels=0.\n",
                        "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
                        "Beginning AutoGluon training ... Time limit = 2673s\n",
                        "AutoGluon will save models to \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\ag_models\\spaceship_autogluon_best_quality_v3\"\n",
                        "Train Data Rows:    8693\n",
                        "Train Data Columns: 25\n",
                        "Label Column:       Transported\n",
                        "Problem Type:       binary\n",
                        "Preprocessing data ...\n",
                        "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
                        "Using Feature Generators to preprocess the data ...\n",
                        "Fitting AutoMLPipelineFeatureGenerator...\n",
                        "\tAvailable Memory:                    8863.48 MB\n",
                        "\tTrain Data (Original)  Memory Usage: 0.80 MB (0.0% of available memory)\n",
                        "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
                        "\tStage 1 Generators:\n",
                        "\t\tFitting AsTypeFeatureGenerator...\n",
                        "\t\t\tNote: Converting 17 features to boolean dtype as they only contain 2 unique values.\n",
                        "\tStage 2 Generators:\n",
                        "\t\tFitting FillNaFeatureGenerator...\n",
                        "\tStage 3 Generators:\n",
                        "\t\tFitting IdentityFeatureGenerator...\n",
                        "\tStage 4 Generators:\n",
                        "\t\tFitting DropUniqueFeatureGenerator...\n",
                        "\tStage 5 Generators:\n",
                        "\t\tFitting DropDuplicatesFeatureGenerator...\n",
                        "\tTypes of features in original data (raw dtype, special dtypes):\n",
                        "\t\t('bool', [])  : 12 | ['HomePlanet_Europa', 'HomePlanet_Mars', 'Destination_PSO J318.5-22', 'Destination_TRAPPIST-1e', 'Deck_B', ...]\n",
                        "\t\t('float', []) :  8 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\t\t('int', [])   :  5 | ['CryoSleep', 'VIP', 'IsSleepZero', 'IsAlone', 'IsVIPDeck']\n",
                        "\tTypes of features in processed data (raw dtype, special dtypes):\n",
                        "\t\t('float', [])     :  8 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\t\t('int', ['bool']) : 17 | ['CryoSleep', 'VIP', 'IsSleepZero', 'IsAlone', 'IsVIPDeck', ...]\n",
                        "\t0.1s = Fit runtime\n",
                        "\t25 features in original data used to generate 25 features in processed data.\n",
                        "\tTrain Data (Processed) Memory Usage: 0.67 MB (0.0% of available memory)\n",
                        "Data preprocessing and feature engineering runtime = 0.1s ...\n",
                        "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
                        "\tTo change this, specify the eval_metric parameter of Predictor()\n",
                        "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
                        "User-specified model hyperparameters to be fit:\n",
                        "{\n",
                        "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
                        "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
                        "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
                        "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
                        "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
                        "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
                        "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
                        "}\n",
                        "Excluded models: [] (Specified by `excluded_model_types`)\n",
                        "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2673.11s of the 2673.09s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.26%)\n",
                        "\t0.8172\t = Validation score   (accuracy)\n",
                        "\t6.65s\t = Training   runtime\n",
                        "\t0.14s\t = Validation runtime\n",
                        "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2658.84s of the 2658.83s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.28%)\n",
                        "\t0.8167\t = Validation score   (accuracy)\n",
                        "\t5.97s\t = Training   runtime\n",
                        "\t0.11s\t = Validation runtime\n",
                        "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2644.69s of the 2644.68s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/8.1 GB\n",
                        "\t0.8025\t = Validation score   (accuracy)\n",
                        "\t1.97s\t = Training   runtime\n",
                        "\t0.62s\t = Validation runtime\n",
                        "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2641.94s of the 2641.93s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/8.6 GB\n",
                        "\t0.8038\t = Validation score   (accuracy)\n",
                        "\t1.69s\t = Training   runtime\n",
                        "\t0.62s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2639.38s of the 2639.37s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.72%)\n",
                        "\t0.8235\t = Validation score   (accuracy)\n",
                        "\t20.8s\t = Training   runtime\n",
                        "\t0.09s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2610.40s of the 2610.39s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/8.5 GB\n",
                        "\t0.7983\t = Validation score   (accuracy)\n",
                        "\t1.72s\t = Training   runtime\n",
                        "\t0.67s\t = Validation runtime\n",
                        "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2607.82s of the 2607.81s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/8.6 GB\n",
                        "\t0.7986\t = Validation score   (accuracy)\n",
                        "\t1.5s\t = Training   runtime\n",
                        "\t0.8s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2605.33s of the 2605.32s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.09%)\n",
                        "\t0.8134\t = Validation score   (accuracy)\n",
                        "\t43.54s\t = Training   runtime\n",
                        "\t0.29s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2550.90s of the 2550.89s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.32%)\n",
                        "\t0.8153\t = Validation score   (accuracy)\n",
                        "\t3.13s\t = Training   runtime\n",
                        "\t0.09s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2541.48s of the 2541.47s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.8085\t = Validation score   (accuracy)\n",
                        "\t135.03s\t = Training   runtime\n",
                        "\t0.19s\t = Validation runtime\n",
                        "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2399.21s of the 2399.19s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.94%)\n",
                        "\t0.8159\t = Validation score   (accuracy)\n",
                        "\t12.84s\t = Training   runtime\n",
                        "\t0.21s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2378.77s of the 2378.76s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.57%)\n",
                        "\t0.8261\t = Validation score   (accuracy)\n",
                        "\t17.47s\t = Training   runtime\n",
                        "\t0.04s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 2352.02s of the 2352.01s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.802\t = Validation score   (accuracy)\n",
                        "\t159.99s\t = Training   runtime\n",
                        "\t0.27s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2182.73s of the 2182.71s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.42%)\n",
                        "\t0.8159\t = Validation score   (accuracy)\n",
                        "\t13.35s\t = Training   runtime\n",
                        "\t0.3s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2161.34s of the 2161.33s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.08%)\n",
                        "\t0.8166\t = Validation score   (accuracy)\n",
                        "\t147.64s\t = Training   runtime\n",
                        "\t0.49s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2006.89s of the 2006.88s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=4.82%)\n",
                        "\t0.8209\t = Validation score   (accuracy)\n",
                        "\t50.14s\t = Training   runtime\n",
                        "\t0.07s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1951.74s of the 1951.73s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.16%)\n",
                        "\t0.8133\t = Validation score   (accuracy)\n",
                        "\t7.89s\t = Training   runtime\n",
                        "\t0.63s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1938.28s of the 1938.27s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
                        "\t0.8102\t = Validation score   (accuracy)\n",
                        "\t325.38s\t = Training   runtime\n",
                        "\t0.3s\t = Validation runtime\n",
                        "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1605.86s of the 1605.85s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.95%)\n",
                        "\t0.8146\t = Validation score   (accuracy)\n",
                        "\t26.46s\t = Training   runtime\n",
                        "\t0.21s\t = Validation runtime\n",
                        "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1571.48s of the 1571.47s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/9.5 GB\n",
                        "\t0.8003\t = Validation score   (accuracy)\n",
                        "\t1.38s\t = Training   runtime\n",
                        "\t0.43s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1569.45s of the 1569.43s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.92%)\n",
                        "\t0.8218\t = Validation score   (accuracy)\n",
                        "\t16.59s\t = Training   runtime\n",
                        "\t0.04s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1542.42s of the 1542.41s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.08%)\n",
                        "\t0.814\t = Validation score   (accuracy)\n",
                        "\t35.81s\t = Training   runtime\n",
                        "\t0.18s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 1497.47s of the 1497.46s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=5.98%)\n",
                        "\t0.8217\t = Validation score   (accuracy)\n",
                        "\t94.65s\t = Training   runtime\n",
                        "\t0.05s\t = Validation runtime\n",
                        "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 1397.07s of the 1397.05s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/10.4 GB\n",
                        "\t0.8046\t = Validation score   (accuracy)\n",
                        "\t1.92s\t = Training   runtime\n",
                        "\t0.59s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 1394.33s of the 1394.32s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.77%)\n",
                        "\t0.8155\t = Validation score   (accuracy)\n",
                        "\t12.97s\t = Training   runtime\n",
                        "\t0.18s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1376.00s of the 1375.99s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.07%)\n",
                        "\t0.8141\t = Validation score   (accuracy)\n",
                        "\t50.99s\t = Training   runtime\n",
                        "\t0.39s\t = Validation runtime\n",
                        "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 1320.29s of the 1320.27s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
                        "\t0.818\t = Validation score   (accuracy)\n",
                        "\t3.05s\t = Training   runtime\n",
                        "\t0.1s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1311.09s of the 1311.08s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
                        "\t0.8044\t = Validation score   (accuracy)\n",
                        "\t339.92s\t = Training   runtime\n",
                        "\t0.32s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 965.16s of the 965.15s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.48%)\n",
                        "\t0.8165\t = Validation score   (accuracy)\n",
                        "\t4.32s\t = Training   runtime\n",
                        "\t0.1s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 955.98s of the 955.97s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
                        "\t0.8063\t = Validation score   (accuracy)\n",
                        "\t217.45s\t = Training   runtime\n",
                        "\t0.66s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 733.57s of the 733.55s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.69%)\n",
                        "\t0.8205\t = Validation score   (accuracy)\n",
                        "\t8.12s\t = Training   runtime\n",
                        "\t0.05s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 720.81s of the 720.80s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.8125\t = Validation score   (accuracy)\n",
                        "\t61.22s\t = Training   runtime\n",
                        "\t0.57s\t = Validation runtime\n",
                        "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 654.81s of the 654.80s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.26%)\n",
                        "\t0.8163\t = Validation score   (accuracy)\n",
                        "\t3.23s\t = Training   runtime\n",
                        "\t0.08s\t = Validation runtime\n",
                        "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 646.29s of the 646.28s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/14.0 GB\n",
                        "\t0.8072\t = Validation score   (accuracy)\n",
                        "\t1.08s\t = Training   runtime\n",
                        "\t0.54s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 644.56s of the 644.55s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.72%)\n",
                        "\t0.8241\t = Validation score   (accuracy)\n",
                        "\t8.43s\t = Training   runtime\n",
                        "\t0.04s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 631.48s of the 631.47s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.8163\t = Validation score   (accuracy)\n",
                        "\t291.02s\t = Training   runtime\n",
                        "\t0.3s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 335.70s of the 335.69s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
                        "\t0.7903\t = Validation score   (accuracy)\n",
                        "\t46.76s\t = Training   runtime\n",
                        "\t0.13s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 283.89s of the 283.88s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.13%)\n",
                        "\t0.8142\t = Validation score   (accuracy)\n",
                        "\t11.43s\t = Training   runtime\n",
                        "\t0.18s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 266.71s of the 266.70s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.8128\t = Validation score   (accuracy)\n",
                        "\t30.31s\t = Training   runtime\n",
                        "\t0.21s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 231.08s of the 231.07s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.41%)\n",
                        "\t0.8214\t = Validation score   (accuracy)\n",
                        "\t25.61s\t = Training   runtime\n",
                        "\t0.11s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 197.16s of the 197.15s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
                        "\t0.8118\t = Validation score   (accuracy)\n",
                        "\t53.88s\t = Training   runtime\n",
                        "\t0.19s\t = Validation runtime\n",
                        "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 133.65s of the 133.64s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.70%)\n",
                        "\t0.8072\t = Validation score   (accuracy)\n",
                        "\t32.37s\t = Training   runtime\n",
                        "\t0.98s\t = Validation runtime\n",
                        "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 88.86s of the 88.85s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/10.5 GB\n",
                        "\t0.8086\t = Validation score   (accuracy)\n",
                        "\t3.12s\t = Training   runtime\n",
                        "\t0.71s\t = Validation runtime\n",
                        "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 84.87s of the 84.85s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.84%)\n",
                        "\t0.822\t = Validation score   (accuracy)\n",
                        "\t20.22s\t = Training   runtime\n",
                        "\t0.03s\t = Validation runtime\n",
                        "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 56.71s of the 56.70s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.06%)\n",
                        "\t0.7993\t = Validation score   (accuracy)\n",
                        "\t63.6s\t = Training   runtime\n",
                        "\t9.47s\t = Validation runtime\n",
                        "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -13.78s of remaining time.\n",
                        "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/10.0 GB\n",
                        "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 1.0}\n",
                        "\t0.8261\t = Validation score   (accuracy)\n",
                        "\t1.64s\t = Training   runtime\n",
                        "\t0.0s\t = Validation runtime\n",
                        "AutoGluon training complete, total runtime = 2688.69s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 24501.4 rows/s (1087 batch size)\n",
                        "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (8693 rows).\n",
                        "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
                        "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\ag_models\\spaceship_autogluon_best_quality_v3\")\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'lb' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 최고 모델의 이름과 점수 가져오기 (수정된 부분)\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# get_model_best() 대신 아래 두 가지 중 하나를 사용합니다.\u001b[39;00m\n\u001b[32m     18\u001b[39m best_model_name = predictor.model_best \n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m best_score = \u001b[43mlb\u001b[49m.loc[lb[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m] == best_model_name, \u001b[33m'\u001b[39m\u001b[33mscore_val\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m]\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m최고 모델: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m내부 검증 정확도(Score_Val): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mNameError\u001b[39m: name 'lb' is not defined"
                    ]
                }
            ],
            "source": [
                "# AutoGluon 학습 설정\n",
                "predictor = TabularPredictor(\n",
                "    label='Transported',\n",
                "    eval_metric='accuracy',\n",
                "    problem_type='binary', \n",
                "    path='ag_models/spaceship_autogluon_best_quality_v3'\n",
                ").fit(\n",
                "    train_data=train_processed,\n",
                "    presets='best_quality',  # 최고 품질 모델 탐색\n",
                "    time_limit=3600,         # 1시간 제한\n",
                "    num_stack_levels=2,      # 스태킹 앙상블 레벨\n",
                "    num_bag_folds=8,         # 배깅 폴드 수\n",
                "    excluded_model_types=[], # 모든 모델 사용\n",
                ")\n",
                "# 모델별 성적표(리더보드) 출력\n",
                "print(\"\\n=== [결과 리더보드] ===\")\n",
                "lb = predictor.leaderboard(extra_info=True)\n",
                "display(lb[['model', 'score_val', 'pred_time_val', 'fit_time']])\n",
                "\n",
                "# 최고 모델의 이름과 점수 가져오기\n",
                "best_model_name = predictor.model_best \n",
                "best_score = lb.loc[lb['model'] == best_model_name, 'score_val'].values[0]\n",
                "\n",
                "print(f\"\\n최고 모델: {best_model_name}\")\n",
                "print(f\"내부 검증 정확도(Score_Val): {best_score:.4f}\")\n",
                "print(\"Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e871876b",
            "metadata": {},
            "source": [
                "하이퍼파라미터 튜닝을 추가, 최고 모델은 WeightedEnsemble_L2로 0.8235점이 나왔습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "b30b7057",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_models/spaceship_autogluon_best_quality_v4\"\n",
                        "Verbosity: 2 (Standard Logging)\n",
                        "=================== System Info ===================\n",
                        "AutoGluon Version:  1.5.0\n",
                        "Python Version:     3.11.14\n",
                        "Operating System:   Windows\n",
                        "Platform Machine:   AMD64\n",
                        "Platform Version:   10.0.22631\n",
                        "CPU Count:          16\n",
                        "Pytorch Version:    2.9.1+cpu\n",
                        "CUDA Version:       CUDA is not available\n",
                        "Memory Avail:       10.40 GB / 31.72 GB (32.8%)\n",
                        "Disk Space Avail:   251.96 GB / 476.83 GB (52.8%)\n",
                        "===================================================\n",
                        "Presets specified: ['best_quality']\n",
                        "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
                        "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=8, num_bag_sets=1\n",
                        "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
                        "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
                        "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
                        "\t\tContext path: \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\ag_models\\spaceship_autogluon_best_quality_v4\\ds_sub_fit\\sub_fit_ho\"\n",
                        "Leaderboard on holdout data (DyStack):\n",
                        "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
                        "0         LightGBMXT_BAG_L1       0.817805   0.818041    accuracy        0.666723       0.063853    2.567944                 0.666723                0.063853           2.567944            1       True          1\n",
                        "1   RandomForestGini_BAG_L1       0.814700   0.802770    accuracy        0.363031       0.499128    1.170451                 0.363031                0.499128           1.170451            1       True          3\n",
                        "2     NeuralNetTorch_BAG_L2       0.814700   0.821017    accuracy        2.794687       1.274039  202.587187                 0.220097                0.357071         111.075952            2       True         13\n",
                        "3   RandomForestGini_BAG_L3       0.813665   0.822700    accuracy        3.594363       2.834259  254.205319                 0.247119                0.620863           2.061983            3       True         17\n",
                        "4      LightGBMLarge_BAG_L1       0.812629   0.815193    accuracy        0.073367       0.060734    2.459161                 0.073367                0.060734           2.459161            1       True          2\n",
                        "5            XGBoost_BAG_L1       0.812629   0.815193    accuracy        0.155629       0.061658    2.582547                 0.155629                0.061658           2.582547            1       True          5\n",
                        "6           CatBoost_BAG_L2       0.811594   0.827359    accuracy        2.616052       0.974625  116.402468                 0.041462                0.057657          24.891233            2       True         11\n",
                        "7       WeightedEnsemble_L3       0.811594   0.827359    accuracy        2.619551       0.975617  116.546299                 0.003499                0.000992           0.143831            3       True         14\n",
                        "8           CatBoost_BAG_L1       0.809524   0.822441    accuracy        1.128946       0.027001    8.435849                 1.128946                0.027001           8.435849            1       True          4\n",
                        "9       WeightedEnsemble_L2       0.809524   0.822441    accuracy        1.132029       0.028506    8.537055                 0.003083                0.001505           0.101206            2       True          7\n",
                        "10          CatBoost_BAG_L3       0.806418   0.831759    accuracy        3.386730       2.243327  266.780010                 0.039486                0.029931          14.636673            3       True         18\n",
                        "11      WeightedEnsemble_L4       0.806418   0.831759    accuracy        3.388756       2.246251  267.334559                 0.002026                0.002924           0.554549            4       True         21\n",
                        "12    NeuralNetTorch_BAG_L3       0.806418   0.826582    accuracy        3.547217       2.489575  324.433951                 0.199973                0.276178          72.290615            3       True         20\n",
                        "13        LightGBMXT_BAG_L2       0.805383   0.825029    accuracy        2.633299       1.033478   99.681418                 0.058709                0.116511           8.170183            2       True          8\n",
                        "14           XGBoost_BAG_L3       0.805383   0.828912    accuracy        3.557940       2.315139  260.136357                 0.210696                0.101743           7.993021            3       True         19\n",
                        "15        LightGBMXT_BAG_L3       0.804348   0.826453    accuracy        3.374522       2.241566  255.352307                 0.027278                0.028170           3.208970            3       True         15\n",
                        "16     LightGBMLarge_BAG_L3       0.804348   0.830982    accuracy        3.385676       2.259068  256.114534                 0.038432                0.045672           3.971197            3       True         16\n",
                        "17  RandomForestGini_BAG_L2       0.803313   0.818170    accuracy        2.778418       1.448132   93.880088                 0.203827                0.531164           2.368853            2       True         10\n",
                        "18     LightGBMLarge_BAG_L2       0.800207   0.826323    accuracy        2.621835       1.029409   98.949959                 0.047244                0.112441           7.438724            2       True          9\n",
                        "19           XGBoost_BAG_L2       0.800207   0.825806    accuracy        2.775905       1.038552   98.198391                 0.201314                0.121584           6.687156            2       True         12\n",
                        "20    NeuralNetTorch_BAG_L1       0.798137   0.804840    accuracy        0.186895       0.204595   74.295283                 0.186895                0.204595          74.295283            1       True          6\n",
                        "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
                        "\t496s\t = DyStack   runtime |\t3104s\t = Remaining runtime\n",
                        "Starting main fit with num_stack_levels=0.\n",
                        "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
                        "Beginning AutoGluon training ... Time limit = 3104s\n",
                        "AutoGluon will save models to \"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\ag_models\\spaceship_autogluon_best_quality_v4\"\n",
                        "Train Data Rows:    8693\n",
                        "Train Data Columns: 25\n",
                        "Label Column:       Transported\n",
                        "Problem Type:       binary\n",
                        "Preprocessing data ...\n",
                        "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
                        "Using Feature Generators to preprocess the data ...\n",
                        "Fitting AutoMLPipelineFeatureGenerator...\n",
                        "\tAvailable Memory:                    11376.87 MB\n",
                        "\tTrain Data (Original)  Memory Usage: 0.80 MB (0.0% of available memory)\n",
                        "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
                        "\tStage 1 Generators:\n",
                        "\t\tFitting AsTypeFeatureGenerator...\n",
                        "\t\t\tNote: Converting 17 features to boolean dtype as they only contain 2 unique values.\n",
                        "\tStage 2 Generators:\n",
                        "\t\tFitting FillNaFeatureGenerator...\n",
                        "\tStage 3 Generators:\n",
                        "\t\tFitting IdentityFeatureGenerator...\n",
                        "\tStage 4 Generators:\n",
                        "\t\tFitting DropUniqueFeatureGenerator...\n",
                        "\tStage 5 Generators:\n",
                        "\t\tFitting DropDuplicatesFeatureGenerator...\n",
                        "\tTypes of features in original data (raw dtype, special dtypes):\n",
                        "\t\t('bool', [])  : 12 | ['HomePlanet_Europa', 'HomePlanet_Mars', 'Destination_PSO J318.5-22', 'Destination_TRAPPIST-1e', 'Deck_B', ...]\n",
                        "\t\t('float', []) :  8 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\t\t('int', [])   :  5 | ['CryoSleep', 'VIP', 'IsSleepZero', 'IsAlone', 'IsVIPDeck']\n",
                        "\tTypes of features in processed data (raw dtype, special dtypes):\n",
                        "\t\t('float', [])     :  8 | ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', ...]\n",
                        "\t\t('int', ['bool']) : 17 | ['CryoSleep', 'VIP', 'IsSleepZero', 'IsAlone', 'IsVIPDeck', ...]\n",
                        "\t0.1s = Fit runtime\n",
                        "\t25 features in original data used to generate 25 features in processed data.\n",
                        "\tTrain Data (Processed) Memory Usage: 0.67 MB (0.0% of available memory)\n",
                        "Data preprocessing and feature engineering runtime = 0.17s ...\n",
                        "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
                        "\tTo change this, specify the eval_metric parameter of Predictor()\n",
                        "User-specified model hyperparameters to be fit:\n",
                        "{\n",
                        "\t'CAT': [{'depth': 6}],\n",
                        "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {'ag_args': {'name_suffix': 'Large'}}],\n",
                        "\t'XGB': [{'max_depth': 6, 'eta': 0.03}],\n",
                        "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini'}}],\n",
                        "\t'NN_TORCH': [{}],\n",
                        "}\n",
                        "Excluded models: [] (Specified by `excluded_model_types`)\n",
                        "Fitting 6 L1 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3103.61s of the 3103.60s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.21%)\n",
                        "\t0.8172\t = Validation score   (accuracy)\n",
                        "\t8.17s\t = Training   runtime\n",
                        "\t0.18s\t = Validation runtime\n",
                        "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3084.18s of the 3084.17s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.22%)\n",
                        "\t0.8167\t = Validation score   (accuracy)\n",
                        "\t23.83s\t = Training   runtime\n",
                        "\t0.07s\t = Validation runtime\n",
                        "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3048.67s of the 3048.66s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/10.3 GB\n",
                        "\t0.8025\t = Validation score   (accuracy)\n",
                        "\t1.53s\t = Training   runtime\n",
                        "\t0.8s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3046.15s of the 3046.14s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.60%)\n",
                        "\t0.8235\t = Validation score   (accuracy)\n",
                        "\t12.07s\t = Training   runtime\n",
                        "\t0.03s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3028.64s of the 3028.63s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.19%)\n",
                        "\t0.8153\t = Validation score   (accuracy)\n",
                        "\t3.89s\t = Training   runtime\n",
                        "\t0.16s\t = Validation runtime\n",
                        "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3017.82s of the 3017.81s of remaining time.\n",
                        "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
                        "\t0.8085\t = Validation score   (accuracy)\n",
                        "\t177.93s\t = Training   runtime\n",
                        "\t0.25s\t = Validation runtime\n",
                        "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 2832.36s of remaining time.\n",
                        "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/10.3 GB\n",
                        "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
                        "\t0.8235\t = Validation score   (accuracy)\n",
                        "\t0.22s\t = Training   runtime\n",
                        "\t0.0s\t = Validation runtime\n",
                        "AutoGluon training complete, total runtime = 271.7s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 40614.5 rows/s (1087 batch size)\n",
                        "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (8693 rows).\n",
                        "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
                        "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\User\\Desktop\\Github\\sklearn-est15th-realfinal\\Spaceship_Titanic\\ag_models\\spaceship_autogluon_best_quality_v4\")\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== [최종 실험 결과 리더보드] ===\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>model</th>\n",
                            "      <th>score_val</th>\n",
                            "      <th>pred_time_val</th>\n",
                            "      <th>fit_time</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>CatBoost_BAG_L1</td>\n",
                            "      <td>0.823536</td>\n",
                            "      <td>0.026639</td>\n",
                            "      <td>12.065453</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>WeightedEnsemble_L2</td>\n",
                            "      <td>0.823536</td>\n",
                            "      <td>0.027636</td>\n",
                            "      <td>12.288717</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>LightGBMXT_BAG_L1</td>\n",
                            "      <td>0.817209</td>\n",
                            "      <td>0.184413</td>\n",
                            "      <td>8.166241</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>LightGBMLarge_BAG_L1</td>\n",
                            "      <td>0.816749</td>\n",
                            "      <td>0.069990</td>\n",
                            "      <td>23.825557</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>XGBoost_BAG_L1</td>\n",
                            "      <td>0.815254</td>\n",
                            "      <td>0.162071</td>\n",
                            "      <td>3.892431</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>NeuralNetTorch_BAG_L1</td>\n",
                            "      <td>0.808467</td>\n",
                            "      <td>0.248221</td>\n",
                            "      <td>177.933815</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>RandomForestGini_BAG_L1</td>\n",
                            "      <td>0.802485</td>\n",
                            "      <td>0.796788</td>\n",
                            "      <td>1.533454</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                     model  score_val  pred_time_val    fit_time\n",
                            "0          CatBoost_BAG_L1   0.823536       0.026639   12.065453\n",
                            "1      WeightedEnsemble_L2   0.823536       0.027636   12.288717\n",
                            "2        LightGBMXT_BAG_L1   0.817209       0.184413    8.166241\n",
                            "3     LightGBMLarge_BAG_L1   0.816749       0.069990   23.825557\n",
                            "4           XGBoost_BAG_L1   0.815254       0.162071    3.892431\n",
                            "5    NeuralNetTorch_BAG_L1   0.808467       0.248221  177.933815\n",
                            "6  RandomForestGini_BAG_L1   0.802485       0.796788    1.533454"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "최고 모델: WeightedEnsemble_L2\n",
                        "내부 검증 정확도(Score_Val): 0.8235\n"
                    ]
                }
            ],
            "source": [
                "# 저장 경로를 새롭게 지정 (v4로 업데이트)\n",
                "NEW_MODEL_PATH = 'ag_models/spaceship_autogluon_best_quality_v4'\n",
                "\n",
                "# 하이퍼파라미터\n",
                "hyperparameters = {\n",
                "    'CAT': {'depth': 6},\n",
                "    'GBM': [\n",
                "        {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
                "        {'ag_args': {'name_suffix': 'Large'}}\n",
                "    ],\n",
                "    'XGB': {'max_depth': 6, 'eta': 0.03},\n",
                "    'RF': {'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini'}},\n",
                "    'NN_TORCH': {},\n",
                "}\n",
                "\n",
                "predictor_2 = TabularPredictor(\n",
                "    label='Transported',\n",
                "    eval_metric='accuracy',\n",
                "    problem_type='binary', \n",
                "    path=NEW_MODEL_PATH  # 새로운 경로 적용\n",
                ").fit(\n",
                "    train_data=train_processed,\n",
                "    presets='best_quality',\n",
                "    time_limit=3600,\n",
                "    num_stack_levels=2,\n",
                "    num_bag_folds=8,\n",
                "    excluded_model_types=[],\n",
                "    hyperparameters=hyperparameters \n",
                ")\n",
                "\n",
                "print(\"\\n=== [최종 실험 결과 리더보드] ===\")\n",
                "final_lb = predictor_2.leaderboard(extra_info=True)\n",
                "display(final_lb[['model', 'score_val', 'pred_time_val', 'fit_time']])\n",
                "\n",
                "best_model_name = predictor_2.model_best \n",
                "best_score = final_lb.loc[final_lb['model'] == best_model_name, 'score_val'].values[0]\n",
                "\n",
                "print(f\"\\n최고 모델: {best_model_name}\")\n",
                "print(f\"내부 검증 정확도(Score_Val): {best_score:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 결과 확인 및 리더보드"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Computing feature importance via permutation shuffling for 25 features using 5000 rows with 5 shuffle sets...\n",
                        "\t9.26s\t= Expected runtime (1.85s per shuffle set)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                      model  score_test  score_val eval_metric  \\\n",
                        "0  RandomForest_r195_BAG_L1    0.999655   0.804555    accuracy   \n",
                        "1   RandomForestEntr_BAG_L1    0.999655   0.803750    accuracy   \n",
                        "2   RandomForestGini_BAG_L1    0.999655   0.802485    accuracy   \n",
                        "3     ExtraTrees_r42_BAG_L1    0.999655   0.800299    accuracy   \n",
                        "4     ExtraTreesGini_BAG_L1    0.999655   0.798343    accuracy   \n",
                        "5     ExtraTreesEntr_BAG_L1    0.999655   0.798574    accuracy   \n",
                        "6   RandomForest_r39_BAG_L1    0.982515   0.808582    accuracy   \n",
                        "7      LightGBMLarge_BAG_L1    0.963419   0.815944    accuracy   \n",
                        "8      LightGBM_r161_BAG_L1    0.939261   0.814218    accuracy   \n",
                        "9        XGBoost_r33_BAG_L1    0.933855   0.814563    accuracy   \n",
                        "\n",
                        "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
                        "0        0.181439       0.589068   1.921976                 0.181439   \n",
                        "1        0.221563       0.619307   1.688011                 0.221563   \n",
                        "2        0.226050       0.617443   1.974835                 0.226050   \n",
                        "3        0.226655       0.433891   1.381089                 0.226655   \n",
                        "4        0.280149       0.667391   1.716483                 0.280149   \n",
                        "5        0.287384       0.796144   1.495966                 0.287384   \n",
                        "6        0.194948       0.710556   3.116401                 0.194948   \n",
                        "7        0.389562       0.210521  12.837128                 0.389562   \n",
                        "8        0.551845       0.176284  11.425071                 0.551845   \n",
                        "9        0.524475       0.205201  26.463963                 0.524475   \n",
                        "\n",
                        "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
                        "0                0.589068           1.921976            1       True   \n",
                        "1                0.619307           1.688011            1       True   \n",
                        "2                0.617443           1.974835            1       True   \n",
                        "3                0.433891           1.381089            1       True   \n",
                        "4                0.667391           1.716483            1       True   \n",
                        "5                0.796144           1.495966            1       True   \n",
                        "6                0.710556           3.116401            1       True   \n",
                        "7                0.210521          12.837128            1       True   \n",
                        "8                0.176284          11.425071            1       True   \n",
                        "9                0.205201          26.463963            1       True   \n",
                        "\n",
                        "   fit_order  \n",
                        "0         24  \n",
                        "1          4  \n",
                        "2          3  \n",
                        "3         20  \n",
                        "4          6  \n",
                        "5          7  \n",
                        "6         43  \n",
                        "7         11  \n",
                        "8         38  \n",
                        "9         19  \n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\t1.39s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "               importance    stddev       p_value  n  p99_high   p99_low\n",
                        "Spa               0.05496  0.002571  5.726229e-07  5  0.060253  0.049667\n",
                        "VRDeck            0.05152  0.006399  2.798636e-05  5  0.064696  0.038344\n",
                        "FoodCourt         0.04896  0.005009  1.296318e-05  5  0.059273  0.038647\n",
                        "Num               0.03120  0.002302  3.531575e-06  5  0.035940  0.026460\n",
                        "ShoppingMall      0.02992  0.003991  3.712271e-05  5  0.038139  0.021701\n",
                        "RoomService       0.02832  0.003563  2.942794e-05  5  0.035655  0.020985\n",
                        "Side_S            0.02180  0.003169  5.208197e-05  5  0.028324  0.015276\n",
                        "TotalSpending     0.01760  0.003696  2.202512e-04  5  0.025210  0.009990\n",
                        "Age               0.01744  0.002085  2.406254e-05  5  0.021733  0.013147\n",
                        "CryoSleep         0.01404  0.001729  2.702384e-05  5  0.017599  0.010481\n"
                    ]
                }
            ],
            "source": [
                "# 리더보드 출력\n",
                "leaderboard = predictor.leaderboard(train_processed, silent=True)\n",
                "print(leaderboard.head(10))\n",
                "\n",
                "# Feature Importance 확인\n",
                "importance = predictor.feature_importance(train_processed)\n",
                "print(importance.head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 예측 및 제출 파일 생성"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ffa6254c",
            "metadata": {},
            "source": [
                "하이퍼 파라미터 설정 없이 excluded_model_types=[]으로 모든 모델 사용 : 0.8246점, 케글 점수 : 0.81201점"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "submission_v3.csv 저장 완료!\n",
                        "  PassengerId  Transported\n",
                        "0     0013_01         True\n",
                        "1     0018_01        False\n",
                        "2     0019_01         True\n",
                        "3     0021_01         True\n",
                        "4     0023_01         True\n"
                    ]
                }
            ],
            "source": [
                "# 테스트 데이터 예측\n",
                "predictions = predictor.predict(test_processed)\n",
                "\n",
                "# 제출 파일 생성\n",
                "submission = pd.DataFrame({\n",
                "    'PassengerId': test_df['PassengerId'].values,\n",
                "    'Transported': predictions.values\n",
                "})\n",
                "\n",
                "# Boolean 값을 True/False로 변환 (AutoGluon이 이미 boolean으로 예측할 수 있지만 안전장치)\n",
                "submission['Transported'] = submission['Transported'].astype(bool)\n",
                "\n",
                "submission.to_csv('submission_v3.csv', index=False)\n",
                "print(\"submission_v3.csv 저장 완료!\")\n",
                "print(submission.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f6c1d1c1",
            "metadata": {},
            "source": [
                "excluded_model_types=[]에 하이퍼 파라미터 설정 추가 : 0.8235점, 케글 점수 : 0.80804점"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "64005e62",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "submission_v4.csv 저장 완료!\n",
                        "  PassengerId  Transported\n",
                        "0     0013_01         True\n",
                        "1     0018_01        False\n",
                        "2     0019_01         True\n",
                        "3     0021_01         True\n",
                        "4     0023_01        False\n"
                    ]
                }
            ],
            "source": [
                "# 테스트 데이터 예측\n",
                "predictions = predictor_2.predict(test_processed)\n",
                "\n",
                "# 제출 파일 생성\n",
                "submission = pd.DataFrame({\n",
                "    'PassengerId': test_df['PassengerId'].values,\n",
                "    'Transported': predictions.values\n",
                "})\n",
                "\n",
                "# Boolean 값을 True/False로 변환 (AutoGluon이 이미 boolean으로 예측할 수 있지만 안전장치)\n",
                "submission['Transported'] = submission['Transported'].astype(bool)\n",
                "\n",
                "submission.to_csv('submission_v4.csv', index=False)\n",
                "print(\"submission_v4.csv 저장 완료!\")\n",
                "print(submission.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

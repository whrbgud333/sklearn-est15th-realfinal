{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from autogluon.tabular import TabularPredictor\n",
                "import os\n",
                "\n",
                "# 1. Load Data\n",
                "TRAIN_PATH = \"train.csv\"\n",
                "TEST_PATH = \"test.csv\"\n",
                "SUBMISSION_PATH = \"submission/submission_optimized.csv\"\n",
                "MODEL_PATH = \"AutogluonModels/ag-optimized-best-quality\"\n",
                "\n",
                "print(\"Loading data...\")\n",
                "train_df = pd.read_csv(TRAIN_PATH)\n",
                "test_df = pd.read_csv(TEST_PATH)\n",
                "\n",
                "# Combine for consistent preprocessing\n",
                "train_len = len(train_df)\n",
                "all_data = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
                "\n",
                "print(\"Preprocessing data and Engineering Features...\")\n",
                "\n",
                "# --- Feature Engineering (Inherited from Spaceship_1.ipynb) ---\n",
                "\n",
                "# 1. Spending Features\n",
                "spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
                "all_data[spending_cols] = all_data[spending_cols].fillna(0)\n",
                "all_data['TotalSpending'] = all_data[spending_cols].sum(axis=1)\n",
                "\n",
                "# 2. CryoSleep Imputation (Logic: If spending > 0, CryoSleep is False. If 0, likely True)\n",
                "# Note: Notebook logic might be slightly nuanced, but this is the core derivative.\n",
                "all_data.loc[(all_data['CryoSleep'].isna()) & (all_data['TotalSpending'] > 0), 'CryoSleep'] = False\n",
                "all_data.loc[(all_data['CryoSleep'].isna()) & (all_data['TotalSpending'] == 0), 'CryoSleep'] = True\n",
                "all_data['CryoSleep'] = all_data['CryoSleep'].astype(bool)\n",
                "\n",
                "# 3. Age & AgeGroup\n",
                "all_data['Age'] = all_data['Age'].fillna(all_data['Age'].median())\n",
                "\n",
                "def update_age_group(age):\n",
                "    if age <= 4: return 'Baby'\n",
                "    elif age <= 12: return 'Child'\n",
                "    elif age <= 19: return 'Teenager'\n",
                "    elif age <= 40: return 'Adult'\n",
                "    elif age <= 60: return 'Middle Aged'\n",
                "    else: return 'Senior'\n",
                "\n",
                "all_data['AgeGroup'] = all_data['Age'].apply(update_age_group)\n",
                "\n",
                "# 4. VIP Imputation\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['TotalSpending'] == 0), 'VIP'] = False\n",
                "all_data.loc[(all_data['VIP'].isna()) & (all_data['Age'] <= 19), 'VIP'] = False\n",
                "all_data['VIP'] = all_data['VIP'].fillna(False).astype(bool)\n",
                "\n",
                "# 5. Destination Imputation\n",
                "dest_mode = all_data['Destination'].mode()[0]\n",
                "all_data['Destination'] = all_data['Destination'].fillna(dest_mode)\n",
                "\n",
                "# 6. Group & GroupSize (from PassengerId gggg_pp)\n",
                "all_data['Group'] = all_data['PassengerId'].str.split('_').str[0]\n",
                "group_sizes = all_data.groupby('Group').size()\n",
                "all_data['GroupSize'] = all_data['Group'].map(group_sizes)\n",
                "\n",
                "# 7. Surname & FamilySize\n",
                "all_data['Surname'] = all_data['Name'].str.split().str[-1]\n",
                "# Fill Surname within Group if possible\n",
                "all_data['Surname'] = all_data.groupby('Group')['Surname'].ffill()\n",
                "all_data['Surname'] = all_data.groupby('Group')['Surname'].bfill()\n",
                "# Map FamilySize\n",
                "family_counts = all_data['Surname'].value_counts()\n",
                "all_data['FamilySize'] = all_data['Surname'].map(family_counts)\n",
                "all_data.loc[all_data['Surname'].isna(), 'FamilySize'] = 1 # Default for unknown\n",
                "\n",
                "# 8. HomePlanet Imputation\n",
                "all_data['HomePlanet'] = all_data.groupby('Group')['HomePlanet'].ffill()\n",
                "all_data['HomePlanet'] = all_data.groupby('Group')['HomePlanet'].bfill()\n",
                "# Map based on Surname if still missing\n",
                "home_map = all_data.dropna(subset=['HomePlanet']).groupby('Surname')['HomePlanet'].agg(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
                "all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['Surname'].map(home_map))\n",
                "all_data['HomePlanet'] = all_data['HomePlanet'].fillna(all_data['HomePlanet'].mode()[0])\n",
                "\n",
                "# 9. Cabin (Deck/Num/Side)\n",
                "# Split existing\n",
                "all_data[['Deck', 'Num', 'Side']] = all_data['Cabin'].str.split('/', expand=True)\n",
                "# Fill within Group\n",
                "for col in ['Deck', 'Num', 'Side']:\n",
                "    all_data[col] = all_data.groupby('Group')[col].ffill()\n",
                "    all_data[col] = all_data.groupby('Group')[col].bfill()\n",
                "\n",
                "# Process Num (convert to int/float for model can digest numerical relationship if needed, though categorical often okay)\n",
                "# Safest is to treat Num as numeric if possible, or object. Deck/Side are strictly object.\n",
                "# AutoGluon handles both well. Let's ensure no NaNs remain if possible.\n",
                "if all_data['Num'].isna().sum() > 0:\n",
                "    all_data['Num'] = pd.to_numeric(all_data['Num'], errors='coerce')\n",
                "    all_data['Num'] = all_data['Num'].fillna(all_data['Num'].median())\n",
                "\n",
                "# --- Model Preparation ---\n",
                "\n",
                "# Drop high cardinality/ID columns to prevent overfitting\n",
                "cols_to_drop = ['PassengerId', 'Name', 'Cabin', 'Surname', 'Group']\n",
                "# Note: 'Group' is ID-like but used for GroupSize. GroupSize is kept. Group ID itself is not useful for generalization.\n",
                "# Keeping 'Surname' might overfit to specific families not in test? Yes, usage of FamilySize covers the feature value.\n",
                "# So dropping Surname is correct.\n",
                "\n",
                "train_final = all_data.iloc[:train_len].copy().drop(columns=cols_to_drop)\n",
                "test_final = all_data.iloc[train_len:].copy().drop(columns=cols_to_drop)\n",
                "\n",
                "# Ensure target is dropped from test if present (Transported)\n",
                "if 'Transported' in test_final.columns:\n",
                "    test_final = test_final.drop(columns=['Transported'])\n",
                "\n",
                "# Train target\n",
                "label = 'Transported'\n",
                "train_final[label] = train_final[label].astype(bool) # Ensure boolean\n",
                "\n",
                "print(f\"Features used: {list(train_final.columns)}\")\n",
                "print(\"Starting AutoGluon Training...\")\n",
                "\n",
                "# AutoGluon Hyperparameters\n",
                "# Using 'best_quality' preset which usually enables bagging and stacking.\n",
                "# Explicitly setting num_bag_folds and num_stack_levels to ensure high performance as requested.\n",
                "# Time limit set to 3600s (1 hour).\n",
                "\n",
                "hyperparameters = {\n",
                "    'CAT': {'depth': 6}, # Prevent overfitting in CatBoost by limiting depth slightly? Default is often 6-8.\n",
                "    # We can leave others to default or specify empty to use defaults logic of 'best_quality'\n",
                "}\n",
                "\n",
                "predictor = TabularPredictor(\n",
                "    label=label,\n",
                "    eval_metric='accuracy',\n",
                "    path=MODEL_PATH,\n",
                "    problem_type='binary'\n",
                ").fit(\n",
                "    train_data=train_final,\n",
                "    presets='best_quality',\n",
                "    time_limit=3600, # 1 hour\n",
                "    num_bag_folds=8, # High bagging\n",
                "    num_stack_levels=2, # Stacking\n",
                "    # hyperparameters=hyperparameters, # Uncomment to enforce constraints, but 'best_quality' explores well.\n",
                "    # To reduce overfitting gap, using 'included_model_types' might be better IF we knew which overfit.\n",
                "    # Usually GBMs are fine. DeepLearning might overfit on small tabular data.\n",
                "    # exclusion logic:\n",
                "    # excluded_model_types=['NN_TORCH', 'FASTAI'] \n",
                ")\n",
                "\n",
                "print(\"Training Complete.\")\n",
                "print(\"Summary:\")\n",
                "print(predictor.fit_summary())\n",
                "\n",
                "# --- Submission Generation ---\n",
                "\n",
                "print(\"Generating predictions...\")\n",
                "y_pred = predictor.predict(test_final)\n",
                "\n",
                "submission = pd.DataFrame({\n",
                "    'PassengerId': test_df['PassengerId'], # Use original test_df to ensure correct ID matching\n",
                "    'Transported': y_pred\n",
                "})\n",
                "\n",
                "if not os.path.exists('submission'):\n",
                "    os.makedirs('submission')\n",
                "\n",
                "submission.to_csv(SUBMISSION_PATH, index=False)\n",
                "print(f\"Submission saved successfully to {SUBMISSION_PATH}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
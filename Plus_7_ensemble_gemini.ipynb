{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AutoGluon Ensemble for California Housing Dataset\n",
                "\n",
                "이 노트북은 AutoGluon을 사용하여 **California Housing** 데이터를 예측하는 회귀 모델을 만듭니다.\n",
                "요청하신 다음 모델들을 포함하여 튜닝하고 앙상블(Voting, Stacking)합니다.\n",
                "\n",
                "- GBM (LightGBM)\n",
                "- XGBoost\n",
                "- CatBoost\n",
                "- Random Forest\n",
                "- Weighted Ensemble (Voting)\n",
                "- Stacking (via AutoGluon capabilities)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# AutoGluon 설치가 필요하면 아래 주석을 해제하고 실행하세요.\n",
                "# !pip install autogluon"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.datasets import fetch_california_housing\n",
                "from sklearn.model_selection import train_test_split\n",
                "from autogluon.tabular import TabularDataset, TabularPredictor\n",
                "\n",
                "# numpy 소수점 설정\n",
                "np.set_printoptions(precision=4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "baaecf3d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting ipywidgets\n",
                        "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
                        "Requirement already satisfied: comm>=0.1.3 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
                        "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipywidgets) (9.9.0)\n",
                        "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
                        "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
                        "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
                        "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
                        "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
                        "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
                        "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
                        "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
                        "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
                        "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
                        "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
                        "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
                        "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
                        "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
                        "Requirement already satisfied: wcwidth in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
                        "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
                        "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
                        "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
                        "Requirement already satisfied: pure_eval in c:\\users\\user\\miniconda3\\envs\\ds\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
                        "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
                        "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
                        "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
                        "   ---------------------------------------- 914.9/914.9 kB 10.4 MB/s  0:00:00\n",
                        "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
                        "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
                        "   ---------------------------------------- 2.2/2.2 MB 17.7 MB/s  0:00:00\n",
                        "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
                        "\n",
                        "   ---------------------------------------- 0/3 [widgetsnbextension]\n",
                        "   ------------- -------------------------- 1/3 [jupyterlab_widgets]\n",
                        "   -------------------------- ------------- 2/3 [ipywidgets]\n",
                        "   -------------------------- ------------- 2/3 [ipywidgets]\n",
                        "   -------------------------- ------------- 2/3 [ipywidgets]\n",
                        "   -------------------------- ------------- 2/3 [ipywidgets]\n",
                        "   ---------------------------------------- 3/3 [ipywidgets]\n",
                        "\n",
                        "Successfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install ipywidgets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "b96c5327",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 100/100 [00:05<00:00, 18.79it/s]\n"
                    ]
                }
            ],
            "source": [
                "from tqdm import tqdm\n",
                "import time\n",
                "\n",
                "# 0부터 99까지 반복하며 진행 바를 표시합니다.\n",
                "for i in tqdm(range(100)):\n",
                "    time.sleep(0.05)  # 작업을 시뮬레이션하기 위한 짧은 대기 시간"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 데이터 로드 및 전처리"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "데이터 크기: (20640, 9)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>MedInc</th>\n",
                            "      <th>HouseAge</th>\n",
                            "      <th>AveRooms</th>\n",
                            "      <th>AveBedrms</th>\n",
                            "      <th>Population</th>\n",
                            "      <th>AveOccup</th>\n",
                            "      <th>Latitude</th>\n",
                            "      <th>Longitude</th>\n",
                            "      <th>MedHouseVal</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>8.3252</td>\n",
                            "      <td>41.0</td>\n",
                            "      <td>6.984127</td>\n",
                            "      <td>1.023810</td>\n",
                            "      <td>322.0</td>\n",
                            "      <td>2.555556</td>\n",
                            "      <td>37.88</td>\n",
                            "      <td>-122.23</td>\n",
                            "      <td>4.526</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>8.3014</td>\n",
                            "      <td>21.0</td>\n",
                            "      <td>6.238137</td>\n",
                            "      <td>0.971880</td>\n",
                            "      <td>2401.0</td>\n",
                            "      <td>2.109842</td>\n",
                            "      <td>37.86</td>\n",
                            "      <td>-122.22</td>\n",
                            "      <td>3.585</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>7.2574</td>\n",
                            "      <td>52.0</td>\n",
                            "      <td>8.288136</td>\n",
                            "      <td>1.073446</td>\n",
                            "      <td>496.0</td>\n",
                            "      <td>2.802260</td>\n",
                            "      <td>37.85</td>\n",
                            "      <td>-122.24</td>\n",
                            "      <td>3.521</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>5.6431</td>\n",
                            "      <td>52.0</td>\n",
                            "      <td>5.817352</td>\n",
                            "      <td>1.073059</td>\n",
                            "      <td>558.0</td>\n",
                            "      <td>2.547945</td>\n",
                            "      <td>37.85</td>\n",
                            "      <td>-122.25</td>\n",
                            "      <td>3.413</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>3.8462</td>\n",
                            "      <td>52.0</td>\n",
                            "      <td>6.281853</td>\n",
                            "      <td>1.081081</td>\n",
                            "      <td>565.0</td>\n",
                            "      <td>2.181467</td>\n",
                            "      <td>37.85</td>\n",
                            "      <td>-122.25</td>\n",
                            "      <td>3.422</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
                            "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
                            "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
                            "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
                            "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
                            "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
                            "\n",
                            "   Longitude  MedHouseVal  \n",
                            "0    -122.23        4.526  \n",
                            "1    -122.22        3.585  \n",
                            "2    -122.24        3.521  \n",
                            "3    -122.25        3.413  \n",
                            "4    -122.25        3.422  "
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 데이터 로드\n",
                "housing = fetch_california_housing()\n",
                "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
                "df['MedHouseVal'] = housing.target\n",
                "\n",
                "print(\"데이터 크기:\", df.shape)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train size: (16512, 9)\n",
                        "Test size: (4128, 9)\n"
                    ]
                }
            ],
            "source": [
                "# 학습/테스트 데이터 분리 (8:2)\n",
                "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
                "\n",
                "print(\"Train size:\", train_data.shape)\n",
                "print(\"Test size:\", test_data.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. AutoGluon 모델 학습\n",
                "\n",
                "AutoGluon의 `TabularPredictor`를 사용합니다.\n",
                "- **presets='best_quality'**: Bagging과 Stacking을 자동으로 적용하여 최고의 성능을 목표로 합니다.\n",
                "- **hyperparameters**: GBM, XGB, CAT, RF 등을 명시적으로 지정하여 해당 모델들을 학습에 포함시킵니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Verbosity: 2 (Standard Logging)\n",
                        "=================== System Info ===================\n",
                        "AutoGluon Version:  1.5.0\n",
                        "Python Version:     3.11.14\n",
                        "Operating System:   Windows\n",
                        "Platform Machine:   AMD64\n",
                        "Platform Version:   10.0.22631\n",
                        "CPU Count:          16\n",
                        "Pytorch Version:    2.9.1+cpu\n",
                        "CUDA Version:       CUDA is not available\n",
                        "Memory Avail:       14.88 GB / 31.72 GB (46.9%)\n",
                        "Disk Space Avail:   325.24 GB / 476.83 GB (68.2%)\n",
                        "===================================================\n",
                        "Presets specified: ['best_quality']\n",
                        "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
                        "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
                        "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
                        "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
                        "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
                        "2026-01-28 16:29:56,299\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
                        "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
                        "2026-01-28 16:30:21,823\tINFO worker.py:2014 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
                        "c:\\Users\\User\\miniconda3\\envs\\DS\\Lib\\site-packages\\ray\\_private\\worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
                        "  warnings.warn(\n",
                        "\t\tContext path: \"c:\\Users\\User\\Desktop\\github\\datascience\\scikit-learn\\agModels-california_housing\\ds_sub_fit\\sub_fit_ho\"\n",
                        "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-28 16:30:35,808 E 15536 17364] (gcs_server.exe) gcs_server.cc:303: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Running DyStack sub-fit ...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Beginning AutoGluon training ... Time limit = 111s\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m AutoGluon will save models to \"c:\\Users\\User\\Desktop\\github\\datascience\\scikit-learn\\agModels-california_housing\\ds_sub_fit\\sub_fit_ho\"\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Train Data Rows:    14677\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Train Data Columns: 8\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Label Column:       MedHouseVal\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Problem Type:       regression\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Preprocessing data ...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Using Feature Generators to preprocess the data ...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tAvailable Memory:                    11656.38 MB\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tStage 1 Generators:\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tStage 2 Generators:\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tStage 3 Generators:\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tStage 4 Generators:\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tStage 5 Generators:\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t\t('float', []) : 8 | ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', ...]\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t\t('float', []) : 8 | ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', ...]\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t0.1s = Fit runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t8 features in original data used to generate 8 features in processed data.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.90 MB (0.0% of available memory)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Data preprocessing and feature engineering runtime = 0.1s ...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m User-specified model hyperparameters to be fit:\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m {\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t'GBM': [{}],\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t'XGB': [{}],\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t'CAT': [{}],\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t'RF': [{}],\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m }\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting 4 L1 models, fit_strategy=\"sequential\" ...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 73.87s of the 110.83s of remaining time.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=0.20%)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[36m(_ray_fit pid=27736)\u001b[0m [1000]\tvalid_set's rmse: 0.445414\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t-0.4494\t = Validation score   (-root_mean_squared_error)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t16.3s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t1.29s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting model: RandomForest_BAG_L1 ... Training model for up to 32.82s of the 69.78s of remaining time.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/11.0 GB\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t-0.5041\t = Validation score   (-root_mean_squared_error)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t14.79s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t1.59s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 15.59s of the 52.55s of remaining time.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=3.47%)\n",
                        "\u001b[36m(_ray_fit pid=28988)\u001b[0m \tRan out of time, early stopping on iteration 702.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t-0.4598\t = Validation score   (-root_mean_squared_error)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t12.66s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t0.05s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 110.84s of the 31.44s of remaining time.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/10.4 GB\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.647, 'CatBoost_BAG_L1': 0.353}\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t-0.4448\t = Validation score   (-root_mean_squared_error)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t0.03s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t0.0s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting 4 L2 models, fit_strategy=\"sequential\" ...\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 31.36s of the 31.36s of remaining time.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=0.23%)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t-0.4468\t = Validation score   (-root_mean_squared_error)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t3.14s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t0.08s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting model: RandomForest_BAG_L2 ... Training model for up to 21.64s of the 21.63s of remaining time.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/10.4 GB\n",
                        "\u001b[36m(_ray_fit pid=27056)\u001b[0m \tRan out of time, early stopping on iteration 693.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t-0.4555\t = Validation score   (-root_mean_squared_error)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t22.12s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t1.55s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 110.83s of the -3.16s of remaining time.\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/10.8 GB\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.368, 'LightGBM_BAG_L2': 0.316, 'CatBoost_BAG_L1': 0.211, 'RandomForest_BAG_L2': 0.105}\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t-0.4429\t = Validation score   (-root_mean_squared_error)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t0.07s\t = Training   runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m \t0.0s\t = Validation runtime\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m AutoGluon training complete, total runtime = 114.24s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1427.6 rows/s (2936 batch size)\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\User\\Desktop\\github\\datascience\\scikit-learn\\agModels-california_housing\\ds_sub_fit\\sub_fit_ho\")\n",
                        "\u001b[36m(_dystack pid=12540)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
                        "Leaderboard on holdout data (DyStack):\n",
                        "                 model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
                        "0  WeightedEnsemble_L3      -0.461182  -0.442946  root_mean_squared_error       10.975471       4.575672  69.079520                 0.048770                0.004656           0.072387            3       True          7\n",
                        "1  WeightedEnsemble_L2      -0.462515  -0.444821  root_mean_squared_error        5.546008       1.346101  28.987087                 0.062858                0.002073           0.026552            2       True          4\n",
                        "2      LightGBM_BAG_L1      -0.463064  -0.449383  root_mean_squared_error        2.553498       1.294720  16.297747                 2.553498                1.294720          16.297747            1       True          1\n",
                        "3      LightGBM_BAG_L2      -0.464212  -0.446827  root_mean_squared_error        9.074042       3.019721  46.890068                 2.176979                0.082625           3.138946            2       True          5\n",
                        "4  RandomForest_BAG_L2      -0.469580  -0.455453  root_mean_squared_error        8.749722       4.488391  65.868187                 1.852659                1.551296          22.117065            2       True          6\n",
                        "5      CatBoost_BAG_L1      -0.476862  -0.459811  root_mean_squared_error        2.929652       0.049307  12.662787                 2.929652                0.049307          12.662787            1       True          3\n",
                        "6  RandomForest_BAG_L1      -0.517431  -0.504094  root_mean_squared_error        1.413913       1.593068  14.790588                 1.413913                1.593068          14.790588            1       True          2\n",
                        "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
                        "\t176s\t = DyStack   runtime |\t424s\t = Remaining runtime\n",
                        "Starting main fit with num_stack_levels=1.\n",
                        "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
                        "Beginning AutoGluon training ... Time limit = 424s\n",
                        "AutoGluon will save models to \"c:\\Users\\User\\Desktop\\github\\datascience\\scikit-learn\\agModels-california_housing\"\n",
                        "Train Data Rows:    16512\n",
                        "Train Data Columns: 8\n",
                        "Label Column:       MedHouseVal\n",
                        "Problem Type:       regression\n",
                        "Preprocessing data ...\n",
                        "Using Feature Generators to preprocess the data ...\n",
                        "Fitting AutoMLPipelineFeatureGenerator...\n",
                        "\tAvailable Memory:                    13845.74 MB\n",
                        "\tTrain Data (Original)  Memory Usage: 1.01 MB (0.0% of available memory)\n",
                        "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
                        "\tStage 1 Generators:\n",
                        "\t\tFitting AsTypeFeatureGenerator...\n",
                        "\tStage 2 Generators:\n",
                        "\t\tFitting FillNaFeatureGenerator...\n",
                        "\tStage 3 Generators:\n",
                        "\t\tFitting IdentityFeatureGenerator...\n",
                        "\tStage 4 Generators:\n",
                        "\t\tFitting DropUniqueFeatureGenerator...\n",
                        "\tStage 5 Generators:\n",
                        "\t\tFitting DropDuplicatesFeatureGenerator...\n",
                        "\tTypes of features in original data (raw dtype, special dtypes):\n",
                        "\t\t('float', []) : 8 | ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', ...]\n",
                        "\tTypes of features in processed data (raw dtype, special dtypes):\n",
                        "\t\t('float', []) : 8 | ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', ...]\n",
                        "\t0.2s = Fit runtime\n",
                        "\t8 features in original data used to generate 8 features in processed data.\n",
                        "\tTrain Data (Processed) Memory Usage: 1.01 MB (0.0% of available memory)\n",
                        "Data preprocessing and feature engineering runtime = 0.29s ...\n",
                        "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
                        "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
                        "\tTo change this, specify the eval_metric parameter of Predictor()\n",
                        "User-specified model hyperparameters to be fit:\n",
                        "{\n",
                        "\t'GBM': [{}],\n",
                        "\t'XGB': [{}],\n",
                        "\t'CAT': [{}],\n",
                        "\t'RF': [{}],\n",
                        "}\n",
                        "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
                        "Fitting 4 L1 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBM_BAG_L1 ... Training model for up to 282.55s of the 423.92s of remaining time.\n",
                        "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=0.19%)\n",
                        "\t-0.4487\t = Validation score   (-root_mean_squared_error)\n",
                        "\t22.8s\t = Training   runtime\n",
                        "\t1.61s\t = Validation runtime\n",
                        "Fitting model: RandomForest_BAG_L1 ... Training model for up to 227.54s of the 368.92s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/11.7 GB\n",
                        "\t-0.5013\t = Validation score   (-root_mean_squared_error)\n",
                        "\t18.73s\t = Training   runtime\n",
                        "\t1.82s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L1 ... Training model for up to 206.03s of the 347.41s of remaining time.\n",
                        "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=3.35%)\n",
                        "\t-0.4366\t = Validation score   (-root_mean_squared_error)\n",
                        "\t167.29s\t = Training   runtime\n",
                        "\t0.4s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L1 ... Training model for up to 30.64s of the 172.02s of remaining time.\n",
                        "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=0.14%)\n",
                        "\t-0.4543\t = Validation score   (-root_mean_squared_error)\n",
                        "\t25.09s\t = Training   runtime\n",
                        "\t0.4s\t = Validation runtime\n",
                        "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 137.33s of remaining time.\n",
                        "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/10.9 GB\n",
                        "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.667, 'LightGBM_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.125, 'RandomForest_BAG_L1': 0.042}\n",
                        "\t-0.4343\t = Validation score   (-root_mean_squared_error)\n",
                        "\t0.05s\t = Training   runtime\n",
                        "\t0.0s\t = Validation runtime\n",
                        "Fitting 4 L2 models, fit_strategy=\"sequential\" ...\n",
                        "Fitting model: LightGBM_BAG_L2 ... Training model for up to 137.21s of the 137.20s of remaining time.\n",
                        "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=0.23%)\n",
                        "\t-0.4382\t = Validation score   (-root_mean_squared_error)\n",
                        "\t4.21s\t = Training   runtime\n",
                        "\t0.09s\t = Validation runtime\n",
                        "Fitting model: RandomForest_BAG_L2 ... Training model for up to 124.86s of the 124.85s of remaining time.\n",
                        "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/10.6 GB\n",
                        "\t-0.4476\t = Validation score   (-root_mean_squared_error)\n",
                        "\t37.6s\t = Training   runtime\n",
                        "\t4.01s\t = Validation runtime\n",
                        "Fitting model: CatBoost_BAG_L2 ... Training model for up to 81.02s of the 81.00s of remaining time.\n",
                        "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=2.93%)\n",
                        "\t-0.4355\t = Validation score   (-root_mean_squared_error)\n",
                        "\t16.86s\t = Training   runtime\n",
                        "\t0.05s\t = Validation runtime\n",
                        "Fitting model: XGBoost_BAG_L2 ... Training model for up to 35.86s of the 35.85s of remaining time.\n",
                        "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=0.17%)\n",
                        "\t-0.4402\t = Validation score   (-root_mean_squared_error)\n",
                        "\t8.61s\t = Training   runtime\n",
                        "\t0.09s\t = Validation runtime\n",
                        "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 18.71s of remaining time.\n",
                        "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/10.8 GB\n",
                        "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.4, 'CatBoost_BAG_L2': 0.4, 'XGBoost_BAG_L2': 0.1, 'LightGBM_BAG_L1': 0.05, 'RandomForest_BAG_L2': 0.05}\n",
                        "\t-0.433\t = Validation score   (-root_mean_squared_error)\n",
                        "\t0.09s\t = Training   runtime\n",
                        "\t0.0s\t = Validation runtime\n",
                        "AutoGluon training complete, total runtime = 405.69s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 888.5 rows/s (3303 batch size)\n",
                        "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\User\\Desktop\\github\\datascience\\scikit-learn\\agModels-california_housing\")\n"
                    ]
                }
            ],
            "source": [
                "# 학습 결과 저장을 위한 경로\n",
                "save_path = 'agModels-california_housing'\n",
                "\n",
                "# 타겟 컬럼\n",
                "label = 'MedHouseVal'\n",
                "\n",
                "# 사용할 모델 지정 (GBM=LightGBM)\n",
                "hyperparameters = {\n",
                "    'GBM': {},      # LightGBM\n",
                "    'XGB': {},      # XGBoost\n",
                "    'CAT': {},      # CatBoost\n",
                "    'RF': {},       # Random Forest\n",
                "}\n",
                "\n",
                "predictor = TabularPredictor(label=label, path=save_path, problem_type='regression', eval_metric='rmse').fit(\n",
                "    train_data,\n",
                "    presets='best_quality', # High quality preset (enables stacking/bagging)\n",
                "    hyperparameters=hyperparameters,\n",
                "    time_limit=600,         # 시간 제한 (초), 필요에 따라 늘리세요 (예: 3600)\n",
                "    num_stack_levels=1,     # Stacking 레벨 지정 (0이면 Bagging만, 1 이상이면 Stacking 수행)\n",
                "    num_bag_folds=5         # Bagging Fold 수\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 모델 성능 평가 (Leaderboard)\n",
                "\n",
                "테스트 데이터를 사용하여 학습된 모든 모델의 성능을 비교합니다.\n",
                "- **WeightedEnsemble**: 여러 모델의 예측을 가중 평균하여 만든 Voting 앙상블 모델입니다.\n",
                "- **Stacker**: Stacking을 통해 만들어진 모델들입니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                 model  score_test  score_val  stack_level    fit_time\n",
                        "0  WeightedEnsemble_L3   -0.420905  -0.432958            3  297.083992\n",
                        "1  WeightedEnsemble_L2   -0.423198  -0.434335            2  233.957715\n",
                        "2      CatBoost_BAG_L2   -0.423289  -0.435540            2  250.774108\n",
                        "3      CatBoost_BAG_L1   -0.423296  -0.436624            1  167.285167\n",
                        "4      LightGBM_BAG_L2   -0.423308  -0.438153            2  238.121042\n",
                        "5       XGBoost_BAG_L2   -0.423562  -0.440154            2  242.521442\n",
                        "6      LightGBM_BAG_L1   -0.428762  -0.448697            1   22.804592\n",
                        "7  RandomForest_BAG_L2   -0.429793  -0.447631            2  271.513745\n",
                        "8       XGBoost_BAG_L1   -0.433572  -0.454339            1   25.088161\n",
                        "9  RandomForest_BAG_L1   -0.501292  -0.501281            1   18.731850\n"
                    ]
                }
            ],
            "source": [
                "# 리더보드 출력\n",
                "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
                "\n",
                "# RMSE가 낮은 순서대로 정렬되어 출력됩니다.\n",
                "print(leaderboard[['model', 'score_test', 'score_val', 'stack_level', 'fit_time']])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best model: WeightedEnsemble_L3\n"
                    ]
                }
            ],
            "source": [
                "# 가장 성능이 좋은 모델 확인\n",
                "print(\"Best model:\", predictor.model_best)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 예측 수행\n",
                "테스트 데이터의 일부에 대해 예측을 수행하고 실제 값과 비교해봅니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Actual</th>\n",
                            "      <th>Predicted</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>20046</th>\n",
                            "      <td>0.47700</td>\n",
                            "      <td>0.555330</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3024</th>\n",
                            "      <td>0.45800</td>\n",
                            "      <td>0.751491</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15663</th>\n",
                            "      <td>5.00001</td>\n",
                            "      <td>5.030818</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>20484</th>\n",
                            "      <td>2.18600</td>\n",
                            "      <td>2.456395</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9814</th>\n",
                            "      <td>2.78000</td>\n",
                            "      <td>2.516374</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        Actual  Predicted\n",
                            "20046  0.47700   0.555330\n",
                            "3024   0.45800   0.751491\n",
                            "15663  5.00001   5.030818\n",
                            "20484  2.18600   2.456395\n",
                            "9814   2.78000   2.516374"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_test = test_data[label]\n",
                "test_data_nolab = test_data.drop(columns=[label])\n",
                "\n",
                "# 예측\n",
                "y_pred = predictor.predict(test_data_nolab)\n",
                "\n",
                "# 실제값과 예측값 비교 (상위 5개)\n",
                "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
                "comparison.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Computing feature importance via permutation shuffling for 8 features using 4128 rows with 5 shuffle sets...\n",
                        "\t261.04s\t= Expected runtime (52.21s per shuffle set)\n",
                        "\t82.46s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>importance</th>\n",
                            "      <th>stddev</th>\n",
                            "      <th>p_value</th>\n",
                            "      <th>n</th>\n",
                            "      <th>p99_high</th>\n",
                            "      <th>p99_low</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>Latitude</th>\n",
                            "      <td>1.100240</td>\n",
                            "      <td>0.007640</td>\n",
                            "      <td>2.789868e-10</td>\n",
                            "      <td>5</td>\n",
                            "      <td>1.115971</td>\n",
                            "      <td>1.084509</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Longitude</th>\n",
                            "      <td>1.037359</td>\n",
                            "      <td>0.009422</td>\n",
                            "      <td>8.165002e-10</td>\n",
                            "      <td>5</td>\n",
                            "      <td>1.056759</td>\n",
                            "      <td>1.017959</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>MedInc</th>\n",
                            "      <td>0.305755</td>\n",
                            "      <td>0.005765</td>\n",
                            "      <td>1.515780e-08</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.317625</td>\n",
                            "      <td>0.293885</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>AveOccup</th>\n",
                            "      <td>0.169231</td>\n",
                            "      <td>0.002746</td>\n",
                            "      <td>8.313771e-09</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.174885</td>\n",
                            "      <td>0.163578</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>AveRooms</th>\n",
                            "      <td>0.139872</td>\n",
                            "      <td>0.005526</td>\n",
                            "      <td>2.918132e-07</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.151251</td>\n",
                            "      <td>0.128493</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>HouseAge</th>\n",
                            "      <td>0.056705</td>\n",
                            "      <td>0.003777</td>\n",
                            "      <td>2.349193e-06</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.064483</td>\n",
                            "      <td>0.048927</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>AveBedrms</th>\n",
                            "      <td>0.014482</td>\n",
                            "      <td>0.002274</td>\n",
                            "      <td>7.061248e-05</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.019164</td>\n",
                            "      <td>0.009800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Population</th>\n",
                            "      <td>0.012494</td>\n",
                            "      <td>0.000736</td>\n",
                            "      <td>1.436911e-06</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.014009</td>\n",
                            "      <td>0.010979</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "            importance    stddev       p_value  n  p99_high   p99_low\n",
                            "Latitude      1.100240  0.007640  2.789868e-10  5  1.115971  1.084509\n",
                            "Longitude     1.037359  0.009422  8.165002e-10  5  1.056759  1.017959\n",
                            "MedInc        0.305755  0.005765  1.515780e-08  5  0.317625  0.293885\n",
                            "AveOccup      0.169231  0.002746  8.313771e-09  5  0.174885  0.163578\n",
                            "AveRooms      0.139872  0.005526  2.918132e-07  5  0.151251  0.128493\n",
                            "HouseAge      0.056705  0.003777  2.349193e-06  5  0.064483  0.048927\n",
                            "AveBedrms     0.014482  0.002274  7.061248e-05  5  0.019164  0.009800\n",
                            "Population    0.012494  0.000736  1.436911e-06  5  0.014009  0.010979"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[33m(raylet)\u001b[0m The node with node id: 8cf1c0b8e3b15a39666fa973cb2c29ae502039dc8f659e0aa2657316 and address: 127.0.0.1 and node name: 127.0.0.1 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, etc.) \n",
                        "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n"
                    ]
                }
            ],
            "source": [
                "# Feature Importance 확인\n",
                "# Stacking 모델인 경우 base 모델들의 기여도가 복잡하므로, 단일 베스트 모델이나 feature_importance 함수 사용\n",
                "predictor.feature_importance(test_data)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

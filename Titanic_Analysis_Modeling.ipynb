{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Titanic: High-Accuracy Survival Prediction\n",
                "\n",
                "This notebook implements advanced feature engineering, robust scaling, and an ensemble modeling approach to maximize prediction accuracy on the Titanic dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
                "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "# Load environment variables for Kaggle API\n",
                "load_dotenv()\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)\n",
                "sns.set(style='whitegrid')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = r'D:\\AI_Study\\GitHub\\DataScience\\pandas\\code\\scikit-learn\\data\\titanic'\n",
                "train_df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
                "test_df = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
                "\n",
                "full_data = [train_df, test_df]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Advanced Feature Engineering (V2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for dataset in full_data:\n",
                "    # 1. Title Extraction\n",
                "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
                "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
                " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
                "    dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
                "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
                "    \n",
                "    # 2. Family Features\n",
                "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
                "    dataset['IsAlone'] = 0\n",
                "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
                "    \n",
                "    # 3. Cabin / Deck Extraction\n",
                "    dataset['Deck'] = dataset['Cabin'].str.slice(0,1).fillna('N')\n",
                "    \n",
                "    # 4. Fill Missing Values (More Granular)\n",
                "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
                "    dataset['Fare'] = dataset['Fare'].fillna(train_df['Fare'].median())\n",
                "    \n",
                "    # Grouped Age Imputation\n",
                "    dataset['Age'] = dataset.groupby(['Sex', 'Pclass', 'Title'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
                "\n",
                "    # 5. New Interaction: Fare per Person\n",
                "    dataset['Fare_per_Person'] = dataset['Fare'] / dataset['FamilySize']\n",
                "    \n",
                "    # 6. Interaction: Age * Class\n",
                "    dataset['Age_Class'] = dataset['Age'] * dataset['Pclass']\n",
                "\n",
                "# Numeric Mapping\n",
                "for dataset in full_data:\n",
                "    dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
                "    \n",
                "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
                "    dataset['Title'] = dataset['Title'].map(title_mapping).fillna(0)\n",
                "    \n",
                "    embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\n",
                "    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping).astype(int)\n",
                "    \n",
                "    deck_mapping = {'N':0, 'C':1, 'B':2, 'D':3, 'E':4, 'A':5, 'F':6, 'G':7, 'T':8}\n",
                "    dataset['Deck'] = dataset['Deck'].map(deck_mapping).astype(int)\n",
                "\n",
                "# Final column cleanup\n",
                "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']\n",
                "train_processed = train_df.drop(drop_elements, axis=1)\n",
                "test_processed = test_df.drop(drop_elements, axis=1)\n",
                "\n",
                "print(\"Processed Columns:\", train_processed.columns.tolist())\n",
                "train_processed.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Scaling & Split\n",
                "\n",
                "Scaling is important for models like SVC and Logistic Regression."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = train_processed.drop('Survived', axis=1)\n",
                "y = train_processed['Survived']\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "test_scaled = scaler.transform(test_processed)\n",
                "\n",
                "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Modeling & Ensembling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "classifiers = [\n",
                "    ('rf', RandomForestClassifier(n_estimators=500, max_depth=6, min_samples_split=10, random_state=42)),\n",
                "    ('gb', GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=3, random_state=42)),\n",
                "    ('et', ExtraTreesClassifier(n_estimators=500, max_depth=6, random_state=42)),\n",
                "    ('svc', SVC(probability=True, kernel='rbf', C=1.0, gamma='auto', random_state=42)),\n",
                "    ('lr', LogisticRegression(solver='liblinear', random_state=42))\n",
                "]\n",
                "\n",
                "vc = VotingClassifier(estimators=classifiers, voting='soft')\n",
                "\n",
                "# CV Score\n",
                "cv_scores = cross_val_score(vc, X_scaled, y, cv=10)\n",
                "print(f\"Average 10-Fold CV Accuracy: {cv_scores.mean():.4f}\")\n",
                "\n",
                "vc.fit(X_scaled, y)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Final Submission & Data Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate submission\n",
                "predictions = vc.predict(test_scaled)\n",
                "submission = pd.DataFrame({\"PassengerId\": test_df[\"PassengerId\"], \"Survived\": predictions})\n",
                "submission.to_csv(os.path.join(data_path, 'submission.csv'), index=False)\n",
                "\n",
                "# Save refined numeric CSVs\n",
                "train_out = pd.DataFrame(X_scaled, columns=X.columns)\n",
                "train_out['Survived'] = y.values\n",
                "test_out = pd.DataFrame(test_scaled, columns=X.columns)\n",
                "\n",
                "train_out.to_csv(os.path.join(data_path, 'titanic_refined_train.csv'), index=False)\n",
                "test_out.to_csv(os.path.join(data_path, 'titanic_refined_test.csv'), index=False)\n",
                "print(\"Refined CSVs and submission saved.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Submit to Kaggle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!kaggle competitions submit -c titanic -f {os.path.join(data_path, 'submission.csv')} -m \"Final High-Accuracy Submission\"\n",
                "!kaggle competitions submissions -c titanic"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
